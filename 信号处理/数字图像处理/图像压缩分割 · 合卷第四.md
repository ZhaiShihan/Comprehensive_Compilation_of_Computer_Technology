### 壹  图像压缩

#### 述：
#####
#####

###### · 图像压缩基础：
· 图像压缩的必要性：
数字图像具有数据量大、信息量大的特点，这给图像的传输、处理和存储带来了极大的困难
![|450](../../图像处理图4-1.png)
                          （图一：人类社会经历的四种计算范式）
![|450](../../图像处理图4-2.png)
                             （图二：万物互联时代的大数据）
· 如果不采取相应的措施，巨大的图像数据量不仅会超出计算机的存储和处理能力，而且在现有通信信道的传输速率下，也难以满足这些信息的实时或准实时传输需求
· 因此，为了存储、处理和传输这些图像数据，必须想办法减少表示图像的数据量，也就是需要对数字图像进行压缩
· 以动态视频为例：
	· 数字高清：$1080i/50Hz$：
	· $1920*1080*50*3=311 040 000 字节/秒$
	· 一小时视频不压缩的数据量为 $1043GB$！
·  视频信号需要的传输率：$2376Mb/s$

· 图像压缩系统主要包括图像压缩和解压缩两部分，前者是对图像信息进行压缩和编码，通常在图像存储、处理和传输前进行；后者是对压缩图像进行解压缩和解码以还原原图像或其近似图像
· 因此，图像压缩和解压缩也常称为<font color="#ffc000">图像编码和图像解码</font>
· 图像压缩涉及的内容很多，通常针对不同的应用目的会使用不同的压缩方法
· 本章将介绍图像压缩的基本原理、常见的图像压缩方法以及图像压缩的国际标准

· 图像压缩的起源：香农信息论
~~~
   “投身信息产业的怀抱三十年了，我有时也在想：信息何以会具备如此强大的力量？它的力量来自哪里？我们又该如何驾驭这一力量？在这三十年间，信息极大地释放了人类的能量，它所创造的价值超过了之前五千年的财富总和，但“信息”依然是个大家耳熟能详却又含义模糊的词。信息是人的镜子，它在技术更新与模式兴替中展现出变化万端的色彩。但我们回视人的心灵，却发现它在千百年来并没有太多的变化。科技的互联网不能描述信息的全部，信息只有作用于思维，才能显示出强大的力量。” ------雷军
~~~

· **信息量**：
· 一个信息如果能传递给我们许多原先未知的内容，我们就认为这个信息很有意义，其包含的信息量大；反之，则信息量小
· 对于一个随机事件 $x$，如果它出现的概率是 $p(x)$，则该事件包含的信息量定义为：$$I(x)=\log_2{\frac{1}{p(x)}}=-\log_2{p(x)}$$
· <font color="#ff337d">口诀</font>：<font color="#00ff7c">“付出一对 2p”</font>
· 若 $p(x)=1$（即该事件总发生），则 $I(x)=0$
· 信息量具有非负性
· 信息量的单位：
	· 底为 $2$ 时，单位为*比特（bit）*
	· 底为 $e$ 时，单位为*奈特（Nat）*
	· 底为 $10$ 时，单位为*哈特*

· **信息熵**：
· 信息熵是信息论中用于度量信息量的概念
· 信息熵指一组数据所携带的平均信息量
· 设信源 $x$ 为 $x=\{x_1, x_2,\ldots,x_n\}$，其概率分布 $p(x)$ 为 $p(x)=\{p(x_1), p(x_2),\ldots, p(x_n)\}$，则信息熵定义为：$$H=-\Sigma_{i=1}^n\ p(x_i)\ \log_2{p(x_i)}$$
· 上式实际上是*信源中每个符号的信息量按其概率相加的结果*，具体到数字图像中，$x_i$ 相当于灰度级，$p(x_i)$ 相当于灰度级 $x_i$ 出现的概率，图像的信息熵则表示该图像各灰度级的平均比特数或图像所含的平均信息量
· 信息熵就是<font color="#ffc000">“加权信息量”</font>

· **平均编码长度**：$$R=\Sigma_{i=1}^n\beta_i p(x_i)$$$\beta_i$ 为第 $i$ 个码字 $x_i$ 的长度（二进制），$p(x_i)$ 为 $x_i$ 出现的概率

· **编码效率**：
· 定义为原始图像的信息熵 $H$ 和图像平均编码长度 $R$ 的比值，即：$$\eta=\frac{H}{R}$$压缩后每个元素的平均码长越短，编码效率越高
· 理解成 $R$ 是人说话，$H$ 是这句话的信息密度，能用最少的话表述清楚信息的，$\eta$ 越大，“编码”效率越高

· **压缩比**：
· 设原始图像每个像素的平均编码长度为 $b_1$，编码后压缩图像每个像素的平均编码长度为 $b_2$
· 压缩比：$$C=\frac{b_1}{b_2}$$压缩比越大，压缩算法性能越高，压缩效果越好

· **无噪声编码定理/香农第一定理**：
· 对信源的每个信源符号编码可达到的最⼩平均码字⻓度
· 如果对信源符号集中的 $n$ 个符号编码，对应单符号信源的 $n$ 阶扩展信源的码字平均⻓度 $L_{avg}$ 与 $n$ 的⽐值可任意接近 $H(u)$，即 $H(u)$ 是其下限
· $n$ 个符号编码的信息熵是 $n\cdot H(u)$，香农第一定理说明 $L^{'}_{avg}$ 永远不可能小于 $H(u)$
· 编码效率：$$\eta=n\frac{H(u)}{L^{'}_{avg}}\ \ \ \ 无损信源压缩的极限$$
· 我们可以找到⼀种最优的编码⽅式，使得信源的压缩效果最佳，从⽽提⾼了数据传输的效率

· 概率为 $P(E)$ 的随机事件包含的信息：$$I(E)=-\log{P(E)}$$
· 信源的平均信息称为该信源的熵：$$H=-\Sigma_{j=1}^J\ P(a_j)\ \log{P(a_j)}$$
· 灰度信源的熵：$$\widetilde{H}=-\Sigma_{k=0}^{L-1}P_r(r_k)\log_2p_r(r_k)$$
· 香农第一定理：$$\lim_{n\to\infty}{[\frac{L_{avg,n}}{n}]}=H$$

· **图像压缩的发展**：
· 自 1948 年提出电视信号数字化后，人们就开始了对 图像压缩编码的研究工作，1969 年美国召开第一届“图像编码会议”，标志着图像编码作为一门独立的学科诞生
· 近 20 年，ISO/IEC 关于静止图像的编码标准 JPEG，CCITT 关于电视电话/会议电视的视频编码标准 H.261 和 ISO/IEC 关于活动图像的编码标准 MPEG-1，MPEG-2
![|475](../../图像处理图4-3.png)
                               （图三：图像压缩发展简图）

###### · 图像压缩原理：
· 对数字图像进行压缩通常利用两个基本原理：
· 一是数字图像的相关性：在静态图像的局部邻域内或视频图像相邻帧的对应像素之间往往存在很强的相关性，去除或减少这些相关性，也就是去除或减少图像信息中的冗余度即可对数字图像进行压缩
· 二是人的视觉心理特征：根据人眼视觉特性，人眼的分辨率非常有限，对于灰度和色彩的细微变化不敏感；而且在通常的视觉感知过程中，有些信息相对于其他一些信息并不那么重要

1. **图像冗余**：
· 图像压缩的方法：消除冗余数据
· 数据是用来表示信息的
· 数据冗余的概念：在表示等量的信息时，使用较多数据量的表示方法就包含数据冗余
· 信息论认为：若信源编码的熵大于信源的实际熵，该信源一定存在冗余度（信息熵冗余）

· 相对数据冗余 $R_D$：
· $n_1$ 和 $n_2$ 代表两个表示相同信息的数据集合中所携载信息单元的数量$$R_D=1-\frac{1}{C_R}$$
· $C_R$ 称为压缩率，定义为 $C_R=\frac{n_1}{n_2}$

· 在数字图像中，数据冗余主要有三种：1. 编码冗余，2. 像素间冗余，3. 心理视觉冗余
· 当减少或消除这三种冗余中的一种或多种时，就实现了图像的压缩

· *编码冗余*：
· 编码冗余：如果一个图像的灰度级编码，使用了多于实际需要的编码符号，就称该图像包含了编码冗余
· 对每个信息或事件所赋的符号序列称为码字，而每个码字里的符号个数称为码字的长度
· 编码所用符号构成的集合称为码本
![|425](../../图像处理图4-4.png)
                                （图四：编码冗余的标尺）

· *像素间冗余*：
· 空间和时间冗余：
	· 反映静止图像中像素之间的空间相关（结构、几何关系等）和 视频序列中相邻帧之间的时间相关
	· 如果图像中像素之间存在空间和时间相关，则单个像素携带的信息相对较少
· 对于一幅图像，很多单个像素对视觉的贡献是冗余的，它的值可以通过与它相邻的像素值为基础进行预测
![|700](../../图像处理图4-5.png)
                               （图五：像素的空间相关）

· *心理视觉冗余*：
· 由于眼睛对所有视觉信息感受的灵敏度不同，在正常视觉处理过程中各种信息的相对重要程度也不同
· 有些信息在通常的视觉过程中与另外一些信息相比并不那么重要，这些信息被认为是心理视觉冗余的，去除这些信息并不会明显降低图像质量
· 心理视觉冗余压缩：
	· 心理视觉冗余压缩是不可恢复的，它表示从一个范围很宽的输入集合到一个有限个输出值的集合的映射，这种映射是不可逆的
	· 消除心理视觉冗余数据会导致一定量信息的丢失，这一过程通常称为<font color="#ffc000">量化</font>

| 冗余类型   | 来源              | 特点         | 压缩方法        | 是否可逆 | 适用场景         |
| :----- | :-------------- | :--------- | :---------- | :--- | :----------- |
| 编码冗余   | 非最优编码方法         | 与编码符号效率有关  | 哈夫曼编码、算术编码等 | 可逆   | 任意场景，尤其是静态图像 |
| 像素间冗余  | 像素值的空间或时间相关性    | 数据之间的相关性   | 预测编码、帧间差分等  | 可逆   | 静态图像和视频序列    |
| 心理视觉冗余 | 人眼对不同信息的感知灵敏度不同 | 去除人眼不敏感的信息 | 量化、频率域压缩等   | 不可逆  | 对质量要求低的图像和视频 |

2. **图像无损压缩与有损压缩**：
· 图像压缩一般分为两类：
	· 无损压缩：在压缩和解压缩过程中没有信息损失
	· 有损压缩：能取得较高的压缩率，但压缩后不能通过解压缩恢复原状
![|500](../../图像处理图4-6.png)
                              （图六：图像压缩编码的分类）

3. **图像保真度**：
· 客观保真度准则是指所损失的信息量可用编码输入原始图像与压缩解码输出还原图像的某个确定函数表示，不受观察者主观因素的影响
· 最常用的客观保真度准则以解压后还原图像和原始图像的差值为基础，主要有均方根误差、均方根信噪比和峰值信噪比三种形式

· *客观保真度准则*：
· $f(x,y)$ 和 $\hat{f}(x,y)$ 之间误差 $e(x,y)$：$$e(x,y)=\hat{f}(x,y)-f(x,y)$$
· 平均误差的平方根：$$e_{rms}=[\Sigma_{x=0}^{M-1}\Sigma_{y=0}^{N-1}[\hat{f}(x,y)-f(x,y)]^2]^{\frac{1}{2}}$$
· 均方信号比：$$SNR_{ms}=\frac{\Sigma_{x=0}^{M-1}\Sigma_{y=0}^{N-1}\hat{f}(x,y)^2}{\Sigma_{x=0}^{M-1}\Sigma_{y=0}^{N-1}[\hat{f}(x,y)-f(x,y)]^2}$$

4. **图像格式、容器和压缩标准**：
· 文件格式：组织和存储图像数据的标准方法，相当于高层的信息，定义了数据类型、压缩方法等
· 容器：相当于一个存放压缩以后的数据的东西
· 压缩方法：处在更底层，规定了数据的具体压缩的过程
![|400](../../图像处理图4-7.png)
                           （图七：图像格式、容器和压缩标准）

###### · 基本的无损编码：
· 基本的无损编码：<font color="#ffc000">统计编码</font>，又称为<font color="#ffc000">熵编码</font>，它是根据信源符号出现概率的分布特性而进行的压缩编码
· 在目前图像编码国际标准中，常用的统计编码方法有哈夫曼编码、算术编码、行程编码等
· 统计编码的基本思想：
	· 在信源符号（或消息）和码字之间建立明确的一一对应关系，以便在恢复时能准确地再现原信号
	· 平均码长或码率尽量小

1. **哈夫曼编码**：
· 将需要考虑的符号概率排序，概率最低的两个符号合并为一个 “复合符号”
· 对每个化简后的信源进行编码，从最小的信源开始，一直编码到原始的信源
![|500](../../图像处理图4-8.png)
                                （图八：哈夫曼编码示例）
· 2 个步骤：消减信源符号数量 → 对每个信源符号赋值：
	· 先将信源符号按它们的概率从大到小排列
	· 然后将概率最小的 2 个符号结合得到 1 个组合符号
	· 将这个组合符号与其他尚没有组合的符号一起仍按概率从大到小排
![|400](../../图像处理图4-9.png)
                           （图九：哈夫曼编码的执行流程示意 Ⅰ）
![|400](../../图像处理图4-10.png)
                           （图十：哈夫曼编码的执行流程示意 Ⅱ）

· 哈夫曼码的优点：
1) 是一种<font color="#ffc000">最优变长编码</font>
2) 一种块码（每个信源符号都被映射为一个固定的编码符号序列）
3) 一种即时码（编码串中的每个码字无需参考后续符号就能解码）
4) 是一种可唯一解开的码（任何编码串都只能以一种方式解码）
~~~
· 例：在某码表下：
010100111100 解码后 a3a1a2a2a6
~~~

· 哈夫曼编码的不足：
1) 当对大量符号进行编码时，消减和编码分配的次数很多，构造哈夫曼编码的计算量会很大
2) 考虑牺牲编码效率以减少编码构造的复杂性

2. **算术编码**：
· 算术编码的基本原理是将编码的整个信源符号序列表示成介于 $0$ 和 $1$ 之间的一个实数区间 $[0,1)$，其长度等于该序列的概率
· 然后在该区间内选择一个代表性的小数，转化为二进制作为实际的编码输出
· 信源符号序列中的每个符号都要缩短为一个区间，根据其出现的概率减小区间的大小
· 当信源中的符号数目增加时，编码表示它的区间就越小，表示这一区间所需的二进制位数就越多

· *算术编码的步骤*：
· 编码器在开始时将“当前区间”设置为 $[0,1)$
· 对于输入符号流中的每个符号，编码器执行如下两个步骤：
	· 编码器将“当前区间”分为多个子区间
	· 选择下一个符号对应的子区间，并使它成为新的“当前区间”
· 将整个符号序列处理完后，在 “当前区间”中任取一个数作为该符号序列的算术编码
· 设信源符号中包含 $k$ 个符号，令 $rangehigh$ 为符号初始概率区间的上界，$rangelow$ 为符号的初始概率区间的下界，$high$ 为“当前区间” 的上界，$low$ 为“当前区间”的下界，$range$ 为子区间的长度，$n$ 为编 码字符所包含的符号个数；初始化时，$high(0)=1$，$low(0)=0$，$range(0)=high(0)-low(0)=1.0$；则一个字符编码后新的 $low$、$high$ 和更新的 $range$ 可以按下式计算：$$\begin{cases}low(i+1)=low(i)+range(i)\times rangelow\\ high(i+1)=low(i)+range(i)\times rangehigh\\ range(i+1)=high(i+1)-low(i+1)\end{cases},\ \ \ \ (i=0,1,\ldots,n-1)$$
· 其中，$low(i)$ 和 $range(i)$ 为上一个待编码字符的子区间下界和区间长度；对最后一个字符进行编码时，可以不再计算其区间长度

· 示例：
![|500](../../图像处理图4-11.png)
                            （图十一：算术编码的例题（一））
![|500](../../图像处理图4-12.png)
                            （图十二：算术编码的例题（二））
![|500](../../图像处理图4-13.png)
                            （图十三：算术编码的例题（三））
![|500](../../图像处理图4-14.png)
                            （图十四：算术编码的例题（四））
![|500](../../图像处理图4-15.png)
                            （图十五：算术编码的例题（五））
![|500](../../图像处理图4-16.png)
                            （图十六：算术编码的例题（六））

· 算术编码的缺点：
	· 对错误很敏感，如果有一位发生错误就会导致整个消息解码错
	· 算术操作的计算精度是有限的
	· 对整个消息只产生一个码字，这个码字是在间隔 $[0, 1)$ 中的一个实数，因此解码器在接收到表示这个实数的所有位之前不能进行解码

3. **行程编码**：
· 行程编码也称为游程编码，是指仅存储一个像素值以及具有相同像素值的像素数目的图像数据编码方法
· 行程编码通过这种方式来去除图像多个像素间的相关性，对于某些相同灰度等级成片连续出现的图像具有较高的编码效率
· 行程编码适用于灰度等级不多、数据相关性很强图像的压缩
· 处理行（或列） 重复灰度的图像
· 行程对指定一个新灰度的开始和具有该灰度的连续像素的数量
· 主要适用于压缩二值图像
· BMP 文件格式的 RLE 是行程编码的一种形式
· 两种古老且应用最广的二值图像压缩标准 CCITT Group3 和 4 都采用了行程编码

· 行程编码分为定长编码和变长编码两种：
	· 定长行程编码是指表示行程长度所用的二进制编码的位数固定
	· 变长行程编码是指对不同范围内的行程长度使用不同位数的二进制编码；使用变长的行程编码还需要增加标志位来表明所使用的二进制编码的位数
	· 因此行程编码的结构一般由三部分组成：行程标志、行程长度和重复字符
· 行程编码最基本的形式是一维行程编码；一维行程编码是利用一行上像素的相关性，所以一维行程编码是逐行扫描的

· 设 $(x_1,x_2,\ldots,x_N)$ 为图像中的某一行像素；该行像素由 $k$ 段长度为 $l_i$、灰度值为 $g_i$ 的片段组成，$1leq i\leq k$，那么该行像素可由行程编码表示为：$$(x_1,x_2,\ldots,x_N)\to(g_1,l_1),(g_2,l_2),\ldots,(g_k,l_k)$$
![|450](../../图像处理图4-17.png)
                             （图十七：行程编码的原理）
· 显然，如果这一行上具有相同灰度级的连续像素越多，即行程越长，则编码的效率就会越高

· 示例：
![|450](../../图像处理图4-18.png)
                               （图十八：行程编码的例题）

· 一维行程编码存在一些不足：
	· 主要是只考虑消除同一行像素的相关性，并没有考虑不同行像素之间的相关性
	· 而二维行程编码不仅可以消除同一行像素之间的相关性，而且还可以消除不同行像素之间的相关性；在图像行程编码中多采用<font color="#ffc000">二维行程编码</font>的方式
	· 二维行程编码和一维行程编码类似，只是具有相同字符的长度值表示的是包含相同字符的正方形的边长，即编码时，水平方向和垂直方向的符号数必须相同
![|300](../../图像处理图4-19.png)
                             （图十九：二维行程编码的示例）

4. **LZW 编码**：
· LZW 编码：消除像素间冗余（空间）的无损编码方法
· LZW 编码是基于字典原理的编码方法
· LZW 编码对信源符号的可变长度序列分配固定长度码字，而且不需要了解有关被编码符号出现概率的知识
· 使用 LZW 的文件格式包括 GIF，TIFF 和 PDF 等

· LZW 编码的原理：
	· 提取待编码数据中的不同字符，基于这些字符创建一个与之对应的带有索引的编码表（字典）
	· 然后用编码表中这些字符对应的索引来替代原始数据中的相应字符，从而起到数据压缩的作用
· LZW 编码原理比较简单，不需要有关字符出现的概率信息
· 该编码算法对于顺序输入的序列元素（如字符或字符串）逐一进行编码，并且在编码的同时生成一个编码表
· 如果下一个元素或元素组合在前面已经出现过，那么就沿用编码表中已有的编码；如果没有出现过，则给予新的编码，并把新的编码补充到编码表中
· 这样，元素组合越多，出现频率越高，则数据压缩效果越好

· LZW 编码使用一种很实用的分析算法，称为<font color="#00ffb0">贪婪分析算法</font>
	· 在贪婪分析算法中，每一次分析都要串行检查来自数据流的字符串，从中分解出已经识别的最长的字符串，也就是已经在字典中出现的最长的前缀
	· 用当前前缀 $P$ 加上下一个输入字符也就是当前字符 $C$ 作为该前缀的扩展字符，形成新的扩展字符串——缀-符串（$P+C$）
	· 这个新的缀-符串是否要加到字典中，要看其是否已存在；如果存在，那么这个“缀-符串”就变成前缀，继续输入新的字符，否则就把这个“缀-符串”写到字典中生成一个新的前缀，并给一个索引
![|450](../../图像处理图4-20.png)
                               （图二十：LZW 编码示例 Ⅰ）
![|450](../../图像处理图4-21.png)
                             （图二十一：LZW 编码示例 Ⅱ）

###### · 预测编码：
· 预测编码方法是一种较为实用、被广泛采用的一种压缩编码方法
· 预测编码主要是<font color="#ffc000">减少了数据在时间和空间上的相关性</font>，因而对于时间序列数据有着广泛的应用价值，如语音、运动图像、视频编码
· 预测编码是根据相邻像素之间存在着一定关联性的特点，利用前面一个或多个像素预测下一个像素的值，<font color="#ffc000">然后对实际值和预测值的差（预测误差）进行编码</font>（即一个像素的新信息定义为实际值和预测值的差值）
· 如果预测比较准确，误差就会很小，只对误差数据进行编码，就可以用比较少的比特，从而达到压缩数据的目的
· 预测编码方法可分为<font color="#ffc000">线性预测和非线性预测</font>编码方法
· 根据是否有量化器，预测编码通常又可以分为<font color="#ffc000">无损预测编码和有损预测编码</font>

1. **无损预测编码**：
· 预测编码通过提取每个像素中的新信息并对它们进行编码来消除像素间冗余，这里一个像素的新信息就定义为该像素的实际值与预测值之间的差
· 在预测编码中，若对每个像素的新信息不进行量化而直接进行编码就称之为无损预测编码
· 无损预测编码系统由一个编码器和一个解码器组成，如图二十二，其中，图 a 是编码器，图 b 是解码器
![|475](../../图像处理图4-22.png)
                       （图二十二：无损预测编码的编码器和解码器）
· 在无损预测编码系统中，编码器和解码器拥有相同的预测器；当输入图像的像素序列 $(n=1,2,\ldots)$ 依次进入编码器时，预测器根据之前的若干个输入来产生当前输入像素的预测值，而该预测值被四舍五入为最接近的整数并被用来计算当前输入像素的预测误差，即：$$e_n=f_n-\hat{f}_n$$
· 误差可以用符号编码器借助变长编码进行编码，并作为压缩数据流中的下一个元素传送，而接收端可以根据接收到的码字解码 ，并无误差地恢复 ，即：$$f(n)=e(n)+\hat{f}(n)$$
· 大多数情况下，预测是通过 $m$ 个以前像素的线性组合来生成的，即：$$\hat{f}_n=round[\Sigma_{i-1}^m a_i f_{n-i}]$$其中，$m$ 是线性预测器的阶，$round$ 是表示四舍五入取最接近整数运算的函数，$(i=1,2,\ldots,m)$ 是预测系数；在一维线性预测编码中，上式可以写为：$$\hat{f}(x,y)=round[\Sigma_{i=1}^m a_i f(x,y-i)]$$
· *信号间相关性越大，预测误差方差越小于信号方差，压缩效率也就越高*

· 示例：
![|475](../../图像处理图4-23.png)
                           （图二十三：无损预测编码的例题）

2. **有损预测编码**：
· 有损预测编码系统与无损预测编码系统相比，主要是在无损预测编码的编码器和形成预测误差的那一点之间增加一个量化器，在图二十四中，图 a 是编码器，图 b 是解码器
![|475](../../图像处理图4-24.png)
                       （图二十四：有损预测编码的编码器和解码器）
· 由上图可以看出，为了接纳量化器需要改变无损编码器以使编码器和解码器所产生的预测值能相等，为此将有损预测编码的预测器放在一个反馈环中，这个环的输入是过去预测和与其对应的量化误差的函数：$$f^{'}_n=e^{'}_n+\hat{f}_n$$

· 由于包含量化器，这使得编码器实际上是对量化后的预测误差编码的，量化器导致了不可逆的信息损失；因此，接收端经解码恢复出的信号已经不是真正的

###### · 变换编码：
· 预测编码方法直接在图像空间对像素进行操作，因此是空间域方法，而接下来要介绍的基于图像变换的编码方法，则是变换域方法；变换编码在目前的图像压缩中有着广泛的应用，是除二值图像外几乎所有图像和视频压缩标准中采用的方法
· 变换编码的基本思想是利用某种变换将图像数据由空间域转换到另一个变换域中，得到一批变换系数，然后对这些变换系数进行编码处理，从而实现压缩图像数据的目的
· 由于正交变换具有去相关性和能量集中的作用，能够把空间域中强相关的像素灰度信息转换成能量保持但集中于少数弱相关或不相关的变换域系数，因此变换编码通常采用正交变换的方式
· 而对大多数自然图像，采用正交变换（例如离散傅里叶变换、离散余弦变换等）得到变换系数中大部分的量级很小，变换编码对于此类系数可以进行不很精确的量化（或完全丢弃），而几乎不会产生太大的图像失真

1. **正交变换编码**：
· 正交变换编码部分由 4 个基本模块构成，分别是：子图像划分、正交变换、量化和符号编码
· 正交变换编码时，首先会把一幅输入图像分解为 $d\times d$ 的子图像，并对每一个子图像进行正交变换
· 这里需要说明的是，变换本身并不会起到数据压缩的作用
· 正交变换的目的是使每个子图像内部像素间的相关性下降，并将尽可能多的图像信息集中在变换域中少数变换系数上
· 接下来的量化步骤可以对变换系数中那些幅度大的元素予以保留，而对于其他数量众多的幅度较小的变换系数则选择性地消除或采用较粗量化的方法进行处理
· 显然，由于量化器存在，量化后变换系数与原子图像的量化系数之间必然存在量化误差，从而输入图像和输出图像之间必然存在误差
· 最后，再利用符号编码（通常采用变长编码）方法对量化之后的系数进行编码
![|500](../../图像处理图4-25.png)
                           （图二十五：正交变换编解码模型）

2. **变换编码的数学分析**：
· 在图像变换编码中，通常先将 $N\times N$ 的原始图像 $f(x,y)$ 划分成一系列 $d\times d$ 的子图像，再对每个子图像进行正交变换
· 这样处理的优点是：
1) 可以使正交变换后子图像的能量分布更集中
2) 可以大大减少变换所需运算量：在分块时，若子图像块取小一些，则便于处理，计算速度快，实现简单，但同时分块的边界效应会比较严重；若子图像块取大一些，那么去除图像块间的相关性效果更好，但同时要大大增加运算的复杂度；故图像分块大小的选择应该使相邻子图像之间的相关性保持到可接受的程度，并且将分块的长和宽设定为 $2$ 的次幂；目前，通常采用的子图像大小为 $8\times8$ 或 $16\times16$，即：$f(x,y)=\{f_i(x,y)\ \vert\ i=1,2,\ldots,\frac{N^2}{d^2}\}$

· 设一幅 $N\times N$ 的图像 $f(x,y)$ 为一个 $n$ 维向量 $X$：$$X=[X_0,X_1,X_2,\ldots,X_{n-1}]^T$$式中，$X_0,X_1,X_2,\ldots,X_{n-1}$ 是将图像划分成块后的堆叠向量
· 如一幅 $256\times256$ 的图像，子图像按 $8\times8$ 划分，就可以划分成 $n=\frac{N^2}{d^2}=\frac{256^2}{8^2}=1024$ 个子图像
· 每个子图像可以看成一个 $m=8\times8=64$ 维的向量，即：$$X_0=[x_{00},x_{01},\ldots,x_{0,m-1}]$$$$X_1=[x_{10},x_{11},\ldots,x_{1,m-1}]$$$$\cdots$$$$X_{n-1}=[x_{n-1,0},x_{n-1,1},\ldots,x_{n-1,m-1}]$$$n$ 维向量 $X$ 经正交变换后，输出为 $n$ 维向量 $Y$，即变换系数 $F(u,v)$：$$Y=[Y_0,Y_1,Y_2,\ldots,Y_{n-1}]^T$$
· 设正交变换为 $U$，则 $X$ 和 $Y$ 之间的关系为：$$Y=UX$$由于 $U$ 是正交阵，所以有：$$UU^T=UU^{-1}=I$$这里，$U^T$ 是 $U$ 的转置，$U^{-1}$ 是 $U$ 的逆，$I$ 是单位阵
· 在正交变换编解码系统中传输或存储的是 $Y$，经过反变换可恢复 $X$，即：$$X=U^{'}Y=U^{-1}Y=U^TY$$

· 若在允许失真的情况下，传输或存储只保留 $Y$ 的前 $M$ 个分量，且 $M\textless n$，则得到 $Y$ 的近似值：$$\hat{Y}=[Y_0,Y_1,Y_2,\ldots,Y_{M-1}]^T$$然后可以利用 $Y$ 的近似值来恢复 $X$，得到 $X$ 的近似值：$$\hat{X}=U^T_M\hat{Y}$$其中，$U_M$ 为 $M\times M$ 的矩阵，只要选取合适，就可以保证解压缩图像的失真在允许的范围内
· 这样的话，变换编码关键问题就转化为如何选择合适的正交变换 $U$ 和 $U_M$，使之既能得到最大的压缩率，又不造成严重的失真

3. **K-L 变换**（Karhunen-Loeve）:
· 最佳变换是满足如下两个条件的变换：
1) 能使变换系数之间的相关性全部解除，也就是使变换系数的协方差矩阵为对角阵；如协方差矩阵为对角阵，则解除了包含在相关性中的冗余度，为无失真压缩编码奠定了基础
2) 能使变换系数的方差高度集中：如果协方差矩阵的对角阵中的元素能量主要集中在前 $M$ 项，那么可以保证舍去 $M$ 项之后的若干系数后所造成的截尾误差就尽可能地小，为熵压缩编码提供了条件

· KL 变换是建立在统计特性基础上的一种变换：
	· 一种特征体取方法
	· 最小均方误差意义下的最优正交变换
	· 在消除模式特征之间的相关性、突出差异性方面有最优的效果
· 我们希望原始数据的新的表达在每个维度上不存在（线性）相关性，因为相关性意味着数据的不同维度间不完全独立，就必然存在重复表示的信息，即：<font color="#00ffb0">数据的不同维度的协方差为</font> $0$
· 我们希望由新的基所得到的数据表达的协方差矩阵中，除对角线上的方差元素外，其余所有的协方差元素全部为 $0$（矩阵对角化）

· 协方差矩阵及优化目标：
	· 设原始数据为 $M$ 个 $N$ 维向量，首先将数据每个维度减去各自维度的均值，使每个维度的均值都变为 $0$，记为矩阵 $X$（每一列对应一个样本向量）
	· 求样本 $X$ 的协方差矩阵 $D_X$
	· 求解 $D_X$ 的特征值和特征向量，取前 $k$ 组最大的特征值对应的特征向量组成正交变换矩阵 $P$
	· 基变换矩阵记为矩阵 $P$，则基变换后的数据可以记为：$Y=PX$
· 优化目标是原协方差矩阵与基变换后矩阵协方差矩阵的关系
· 显然，$Y$ 每个维度的均值也为 $0$，因此 $Y$ 的协方差矩阵为：$$D_Y=\frac{1}{M}YY^T=\frac{1}{M}(PX)(PX)^T=\frac{1}{M}PXX^TP^T$$$$=P\frac{1}{M}(XX^T)P^T=PD_XP^T\ \ 目标变换矩阵P：能让原始数据协方差矩阵对角化$$
· 因此，可以通过正交变换使得 $Y$ 的协方差矩阵成为对角阵，即可以找到一个正交变换 $U$ 使变换结果最佳，这也是 K-L 变换的核心

· 协方差矩阵 $D_X$ 是一个实对称矩阵，实对称矩阵不同特征值对应的特征向量必然正交
· $P$ 是协方差矩阵 $D_X$ 的特征向量单位化后按行排列出的矩阵，其中每一行都是 $D_X$ 的一个特征向量
· 如果 $P$ 按照特征值从大到小，将特征向量从上到下排列，则用 $P$ 的前 $k$ 行组成的矩阵乘以原始数据矩阵 $X$，就得到了我们需要的降维后的数据矩阵 $Y$

· 算法步骤：
1) 将原始数据按列组成 $N$ 行 $M$ 列的矩阵 $X$
2) 将 $X$ 的每一行（每个维度）进行零均值化
3) 求出协方差矩阵 $D_X=\frac{1}{M}XX^T$
4) 求出 $D_X$ 的特征值及对应的特征向量
5) 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前 $k$ 行组成矩阵 $P$
6) $Y=PX$ 即为降维到 $k$ 维后的数据

4. **其他变换**：
· 常见的准最佳变换有离散傅里叶变换（DFT）、离散余弦变换（DCT）、离散沃尔什-哈达玛变换（DWHT）、哈尔变换（HT）和斜变换（ST）等
· 这些正交变换都具有 $T$ 的性质，尽管它们的性能比 K-L 变换稍差，但是由于它们都存在快速算法，并且变换矩阵 $T$ 是固定的，因此应用比 K-L 变换更广泛
· 早期的图像变换编码常采用 DFT，由于它具有快速算法并且容易通过硬件实现
· 但是，由于 DFT 是一种复数变换，运算量较大，因而在实际应用中仍存在实时性差的问题
· DWHT 具有 DFT 的快速算法结构，运算量相对于 DFT 却明显减少
· 但是 DWHT 的能量集中能力比 DFT 差一些
· DCT 是 K-L 变换的非常近似的逼近，具有快速算法，运算简单，具有固定的变换阵，并且变换核可分离，因而被应用到了许多压缩系统中
· 各正交变换在变换域能量集中的性能近似比较：
~~~
DWHT HT ————> DFT ————> ST ————> DCT ————> K-L
                    能量集中
劣 ———————————————————————————————————————> 优
~~~

###### · 图像压缩国际标准：
· 与图像相关的国际标准已覆盖了从二值到灰度（彩色）值的静止和运动图像，以及包括视频和音频多种媒体
· 根据各标准所处理对象类型的不同，可以分为：二值图像压缩标准、静止灰度（彩色）图像压缩标准、运动图像压缩标准、多媒体压缩标准；常见的图像压缩编码标准有：JPEG、MPEG、JBIG 及 H.26X 等

1. **二值图像压缩标准**：
· 二值图像指像素只有两种取值的图像，这既可以是由灰度图像分解得到的位平面图像，也可以是直接采集获得的图像（如传真）
- G3 和 G4：
· G3 和 G4 这两个标准是由 CCITT 的两个小组 Group 3 和 Group 4 负责制定的，它们最初是 CCITT 为传真应用而设计的，现也用于其他方面
· G3 采用了非自适应、一维行程编码技术，但是 G3 对每组 $N$ 行（$N=2$ 或 $N=4$）扫描线中的后 $N-1$ 行也可以用二维方式编码；而 G4 是 G3 的一种简化版本，其中只使用二维编码；CCITT 在制定标准期间曾选择一组具有一定代表性的八幅“试验”图用来评判各种压缩方法，它们既包括打印的文字，也包括 用几种语言手写的文字，另外还有少量的线绘图；G3 对它们的压缩率约为 $15:1$，而 G4 的压缩率一般比 G3 要高 $1$ 倍
- JBIG：
· JBIG 是由 ISO 和 ITU 两个组织的二值图联合组（Joint Bilevel Imaging Group，JBIG）于 1991 年制定的，JBIG 的目标之一就是要采用自适应技术解决 G3 和 G4 存在的问题；为解决该问题，JBIG 采用自适应模板和自适应算术编码来改善性能；另外，JBIG 还通过金字塔式的分层编码和分层解码实现渐进（累进）的传输与还原应用；由于采用了自适应技术，JBIG 的编码效率比 G3 和 G4 要高；对于打印字符 的扫描图像，压缩比可提高 $1.1$ 倍 ~ $1.5$ 倍

2. **静态图像压缩标准**：
· 静态图像包括灰度静态图像和彩色静态图像
- JPEG：
· JPEG 是由 ISO 和 CCITT 两个组织于 1986 年成立的联合图像专家组（Joint Picture Expert Group，JPEG）所制定的静态灰度或彩色图像的压缩标准 ，编号为 ISO / IEC10918，全称为“多灰度连续色调静态图像压缩编码”
· 制定 JPEG 标准的目的是满足以下要求：
1) 可大范围调节图像压缩率及其相应的图像保真度，同时编码器是参数可调的，以便使用户应用时可以选择期望的压缩/质量比
2) 能应用于任何连续色调数字源图像（实际应用中可遇到的图像很多，不限制图像的尺寸、色彩空间、像素长宽比等条件），不限制图像的内容（如复杂程度、色彩范围或统计特性等）\
3) 计算复杂性容易控制：不但使 JPEG 压缩标准可以采用软件实现方法在一定能力的 CPU 上完成，而且也可以在可行的成本下易于采用硬件实现
· JPEG 标准为保证通用性，实际上定义了三种编码系统：
1) 基于 DCT 的有损压缩编码：这是 JPEG 的基本系统（必须保证的功能）；这一系统采用顺序模式，可用于绝大多数压缩应用场合
2) 基于分层递增模式：这是 JPEG 的扩展系统，采用了渐进模式，用于高压缩比、高精确度或渐进还原应用的场合
3) 基于空间预测编码 DPCM 的无损压缩编码：这是一个独立系统， 用于无失真应用的场合
· JPEG 的三种编码系统共有四种工作模式：
	· 顺序编码模式
	· 渐进编码模式
	· 无失真编码模式
	· 分层编码模式
· 图像系统如果想与 JPEG 兼容，必须要支持 JPEG 基本系统，但是另一方面，JPEG 没有规定文件格式、图像分辨率或所用彩色空间模型，这样就可以适用于不同应用场合；目前，在不明显降低图像视觉质量的基础上，根据 JPEG 标准常可将图像压缩 $10$ ~ $50$ 倍
![|400](../../图像处理图4-26.png)
                 （图二十六：JPEG 图像压缩标准编码器和解码器基本系统框图）
· 输入图像进入编码器后，经 DCT 变换、量化、变长编码后输出压缩数据，而解码器对于传输过来的压缩后的图像数据实施解码、逆量化、逆 DCT（IDCT）变换，然后将解码后的图像输出
· 解码器和编码器的功能恰好相反，所以它们使用的量化表、码表必须一致，以保证解码准确无误，而对于彩色图像，可以将各个通道分量分别输入，然后对其压缩输出
- JPEG2000：
· 基于 Internet 网络的多媒体应用，给图像编码提出了新的要求
· ISO 于 2000 年 12 月公布了新的 JPEG2000 标准（ISO 15444），其目标是在高压缩率的情况下，有效保证图像传输的质量；JPEG2000 采用以小波变换为主的多分辨率编码方式；JPEG2000 具有一些 JPEG 所没有的优势；JPEG2000 统一了面向静态图像和二值图像的编码方式，将 JPEG 的四种模式集成到一个标准中，是既支持低比率压缩又支持高比率压缩的通用编码方式；相对于 JPEG，JPEG2000 在压缩比比较高的情形下具有明显的优势
· 总体而言，与 JPEG 相比，JPEG2000 压缩性能通常可以提高 20% 以上，并且在压缩比达到 $100:1$ 的情形下，采用 JPEG 压缩的图像一般已经严重失真并开始难以识别了，但采用 JPEG2000 压缩的图像 仍可识别

3. **运动图像压缩标准**：
· MPEG标准是面向运动图像压缩的一个系列标准的总称
· 运动图像压缩标准 MPEG 由 ISO 和 CCITT 于 1988 年成立的活动图像专家组（Moving Picture Expert Group，MPEG）制定
· MPEG 算法编码过程和解码过程是一种非镜像对称算法，其解码过程要比编码过程相对简单一些
· 最初 MPEG 专家组的工作项目是 3 个，即在 1.5Mbps、10Mbps、40Mbps 传输速率下对图像编码，别命名为 MPEG-1、MPEG-2 和 MPEG-3，MPEG-3 后被取消
· 为了满足不同的应用要求，MPEG 又将陆续增加其他一些标准：MPEG-4、MPEG-7、MPEG-21
· 下面简单介绍一下常用的运动图像压缩标准：MPEG-1、MPEG-2 和 MPEG-4
- MPEG-1：
· MPEG-1（ISO/IEC 11172）制定于 1992 年，其全称是“用于数字 存储媒体运动图像及其伴音速率为 1.5Mbps 的压缩编码”
· MPEG-1 主要用于在 CD-ROM 存储运动视频图像，还用于数字电话网络上的视频传输，如非对称数字用户线路（ADSL）、视频点播、教育网络等
· 使用 MPEG-1 的压缩算法，可将一部 120 分钟长的电影压缩到 1.2GB 左右，因此它被广泛地应用于 VCD 制作
· MPEG-1 视频编码为了达到较高的压缩比并且满足随机存取的要求，对这两个方面做了折衷考虑
· MPEG-1 视频编码采用基于块的运动补偿技术减少时间上冗余性，同时采用基于 DCT 变换的方法减少空间上冗余性
· 为了兼顾编解码精度和压缩比，在 MPEG 中将图像分为 3 种类型：I 图像、P 图像和 B 图像：
1) I 图像：又称为帧内编码帧，其利用图像自身的相关性压缩；视频初始帧（第 1 帧）必须是 I 帧，其后每隔若干帧还必须是 I 帧，I 帧在视频序列中起着定位及减小累计误差的作用，要求有较高的编码精度；因此，I 帧的压缩比相对较小
2) P 图像：又称为预测编码帧，P 图像编码时用前面（过去）最靠近 I 图像（或 P 图像）作为参考帧，进行运动估计和补偿；因为 P 图像只对产生运动的坐标位置和运动量进行编码，因此有较大的压缩比；同时，P 图像还要作为参考帧用于前帧或后帧的运动估计与补偿，因此又不能有太大的编码误差
3) B 图像：又称为双向预测帧，B 图像编码时既可以使用最靠近的前一个或后一个图像 I 图像（或 P 图像）作参照，进行运动估计与补偿，也可以同时使用前后两帧图像作为参考帧进行全向运动估计并去平均值作为补偿；因此，B 图像可以得到较准确的运动补偿结果，获得较大的压缩比
· MPEG 采用的运动补偿技术主要用于消除 P 图像和 B 图像在时间上的冗余性，提高压缩效率
- MPEG-2：
· MPEG-2（ISO/IEC 13818）标准制定于 1994 年，它利用网络提供的 $3$ ~ $100$ Mbps 的数据传输率来支持具有更高分辨率图像的压缩和更高的图像质量；MPEG-2 可支持交迭图像序列，支持可调节性编码， 多种运动估计方式；MPEG-2 同时提供了一个较广泛的范围来改变压缩比，以适应不同画面质量、存储容量和带宽的要求
· MPEG-2 在与 MPEG-1 兼容的基础上，实现了低码率和多声道扩展，MPEG-2 可以将一部 120 分钟时长的电影压缩到 $4$ ~ $8$ GB（DVD 质量），其音频编码可提供左右中及两个环绕声道、一个加重低音声道和多达 7 个伴音声道
- MPEG-4：
· 国际标准 MPEG-4 “甚低速率视听编码”于 1998 年发布，它针对低速率下的视频、音频编码，并且更加注重多媒体系统的交互性和灵活性；MPEG-4 属于一种高比率有损压缩算法，主要应用于数字电视、动态图 像、互联网、实时多媒体监控、移动多媒体通信、Internet / Intranet 上的视频流与可视游戏、DVD 上的交互多媒体等方面
· MPEG-4 引入了视听对象（Audio/Visual Objects，AVO），使得更多的交互操作成为可能；视听对象可以是一个孤立的人，也可以是这个人的语音或一段背景音乐等；MPEG-4 对视听对象的操作主要有：采用视听对象来表示听觉、视觉或者视听组合内容；组合已有视听对象来生成复合的视听对象，并生成视听场景；对视听对象的数据灵活地多路合成与同步，以便选择合适的网络来传输这些视听对象数据；允许接收端用户在视听场景中对视听对象进行交互操作等
· 与 MPEG-1 和 MPEG-2 相比，MPEG-4 更适于交互视听服务以及远程监控，其设计目标使它具有更广的适应性和可扩展性；MPEG-4 传输速率可在 $4.8$ ~ $64$ kbps 之间，分辨率为 $176\times144$，可以利用很窄的带宽通过帧还原技术压缩和传输数据


### 贰  图像分割

#### 述：
#####
#####

###### · 图像分割定义：
· <font color="#00ffb0">图像分割</font>是将整个图像分割成若干个互不交叠的非空子区域的过程
· 每个图像子区域的内部是连通的
· 同一子区域内部具有相同或相似的特性，这里的特性可以是灰度、颜色、纹理等

· **图像分割的分类**：
· 图像分割处理实际上就是区分图像中的“前景目标”和“背景”
· 根据图像的某些局部特征的相似性和互斥性，可以把图像分割成若干子区域：
	· 每个子区域内部具有相似（或相同）的特性
	· 相邻子区域的特性不相同
· 具体到灰度图像，其分割的依据就是图像灰度值的两个基本特性：
	· 不同区域交界（边缘）处的灰度突变性
	· 区域内部的灰度相似性
· 图像分割的目的：使输出图像所包含的数据远少于输入图像，但这些数据信息却与图像分析更有关系
![|425](../../图像处理图4-27.png)
                              （图二十七：图像分割的分类 Ⅰ）
![|425](../../图像处理图4-28.png)
                            （图二十八：图像分割的分类 Ⅱ）
![|425](../../图像处理图4-29.png)
                            （图二十九：图像分割的分类 Ⅲ）
· 在图二十九中：a—图像分类，b—对象初始化，c—语义分离，d—实例分割，e—全景分割

###### · 基于边缘的分割方法：
· 图像分割的一种重要途径是通过边缘检测
· 边缘：灰度级具有突变的位置，这一位置表明一个区域的终结与另一个区域的开始
· 通过边缘点的检测，可以将边缘点连接成边缘线，而边缘线围成的区域就是图像分割的结果
· 边缘作为图像的最基本特征广泛存在于目标物与背景以及目标物与目标物之间，因而可以作为图像识别、分类和理解的直接依据
· 边缘检测是所有基于边缘的图像分割方法的第一步
· 边缘检测：
	· 确定图像中某个局部区域是否存在边缘点
	· 若存在需要进一步确定其位置

· 边缘检测—>边缘闭合—>Hough 变换
· 边缘检测：Canny 边缘检测算子平滑—>梯度锐化—>非极大值抑制—>双阈值边缘保留
· 边缘闭合：梯度幅度相近，梯度方向相似，且明显的两个点连接
· Hough 变换，通过 Hough 空间上 $k-q$ 直线或 $\rho-\theta$ 正弦曲线交点检测源图像空间上的直线

1. **边缘检测**：
· 图像中边缘处像素的灰度值是不连续的，这种不连续性可通过求导数来检测；在数字图像处理中，一般使用一阶和二阶导数来检测边缘
· 一阶算子：
	· Robert 算子
	· Prewitt 算子
	· Sobel 算子
· 二阶算子：
	· 拉普拉斯算子
	· Log 算子
· 一阶和二阶经典导数算子构造简单，便于应用，但是这些导数算子依然存在一些问题：
	· 一是容易受图像噪声的影响
	· 二是边缘检测定位精度不够，如拉普拉斯算子常常会产生双边界
	· 三是在噪声等干扰因素影响下，难以得到闭合的边缘

- <font color="#00ffb0">Canny 边缘检测</font>：
· 针对这些问题，John F. Canny 研究了最优边缘检测器所需要的特性，并给出了评价边缘检测算子性能优劣的三个指标：
	· 好的检测率：算法能够尽可能多地标识出图像中的实际边缘
	· 好的定位性能：标识出的边缘要与实际图像中的实际边缘尽可能接近
	· 最小响应：图像中的边缘只能标识一次，并且可能存在的图像噪声不应标识为边缘
· Canny 边缘检测器是高斯函数的一阶导数，是对信噪比与定位之乘积的最优化逼近算子
· 类似于 Marr（LoG）边缘检测方法，也属于先平滑后求导数的方法
~~~
· 科技史表明，层次越高的学者越能用一项代表作体现其水平，诺贝尔奖、菲尔兹数学奖等权威大奖奖励的都是一项具体的科研成果。

冯康—有限元法
薛其坤—量子反常霍尔效应
爱因斯坦—相对论
杨振宁—规范场
丘成桐—卡拉比猜想
~~~
· Canny 边缘检测算子的基本步骤：
1) 利用二维高斯滤波器对图像进行平滑，通过高斯滤波去除图像噪声的影响，常用 $5\times5$ 大小的高斯核，设置 $\sigma=1.4$：$$h(x,y)=e^{-\frac{x^2+y^2}{2\sigma^2}}$$$$B=\frac{1}{159}\begin{bmatrix}2&4&5&4&2\\ 4&9&12&9&4\\ 5&12&15&12&5\\ 4&9&12&9&4\\ 2&4&5&4&2\end{bmatrix}*A$$
2) 利用一阶导数算子检测图像边缘（例如 Sobel 算子），得到每个像素点的梯度值和方向：$$H_h=\begin{bmatrix}-1&1&0\\ -1&1&0\\ 0&0&0\end{bmatrix},\ \ \ \ H_v=\begin{bmatrix}-1&-1&0\\ 1&1&0\\ 0&0&0\end{bmatrix}$$$$G=\sqrt{H_h^2+H_v^2}$$$$\theta=\arctan{\frac{H_v}{H_h}}$$将梯度方向通过四舍五入方法归入到水平/垂直/对角（$0^\degree,45^\degree,90^\degree,135^\degree$），比如 $[0^\degree,22.5^\degree]$ 和 $[157.5^\degree,180^\degree]$ 映射为 $0^\degree$
3) 非极大值抑制（Non-Maximum Suppresion）：
	· 对梯度值进行非极大值抑制，细化边缘
	· “非极大抑制”的基本方法是考虑梯度幅度图中的小邻域（如 $3\times3$），并且比较当前像素与其同梯度方向的相邻像素的梯度值
	· 如果该像素的梯度值不大于相邻像素的梯度值，则将其值置为零；否则将其保留下来
	· 梯度的方向在邻域范围内可以标记为 $0$、$1$、$2$、$3$ 四个方向，非极大值抑制的作用是在邻域范围内，将当前待处理像素与同方向的临近像素进行比较，以决定梯度局部极大值
	· 例如，如果中心像素 $p$ 的梯度方向属于第 $1$ 区，则把 $p$ 的梯度值与它左下和右上的邻近像素的梯度值进行比较，看 $p$ 的梯度值是否是局部极大值；如果是，则保留像素 $p$ 的梯度值；如果不是，就把 $p$ 的梯度值置为 $0$
![|160](../../图像处理图4-30.png)
                           （图三十：将梯度幅度图中的小邻域标号）
	· 非极大值抑制，在计算机视觉任务中得到了广泛的应用，例如边缘检测、人脸检测、目标检测（DPM，YOLO，SSD，Faster R-CNN）等
![|425](../../图像处理图4-31.png)
                          （图三十一：非极大值抑制前后对比）
~~~
· 算法流程：
1. 给出一张图片和上面许多物体检测的候选框（即每个框可能都代表某种物体），但是这些框很可能有互相重叠的部分，我们要做的就是只保留最优的框；假设有 N 个框，每个框被分类器计算得到的分数为 Si，i<=i<=N
2. 建造一个存放待处理候选框的集合 H，初始化为包含全部 N 个框；建造一个存放最优框的集合 M，初始化为空集
3. 将所有集合 H 中的框进行排序，选出分数最高的框 m，从集合 H 移到集合 M
4. 遍历集合 H 中的框，分别于框 m 计算交并比（Interection-over-union，IoU），如果高于某个阈值（一般为 0~0.5），则认为此框与 m 重叠，将此框从集合 H 中去除
5. 回到第 2 步进行迭代，直到集合 H 为空；集合 M 中的框为我们所需
· 核心：不断筛选出不重叠且最有效的框，即图片上所有需要体取的信息
~~~
4) 双阈值边缘连接：
	· 对经过非极大值抑制的梯度图像再利用阈值 $T_1$ 和 $T_2$ 进行两次边缘提取，且可设 $2T_1=T_2$ ，从而可以得到两个边缘图像 $G_{T_1}$ 和 $G_{T_2}$
	· $G_{T_2}$ 使用高阈值得到，因而去除了大部分假边缘和噪声，但同时也损失了很多有用的边缘信息，而 $G_{T_1}$ 保留了较多的边缘信息和噪声
	· 可以以 $G_{T_2}$ 为基础，参照 $G_{T_1}$ 来连接图像的边缘
	· 具体实现时，先在 $G_{T_2}$ 中沿边缘进行扫描，当到达边缘端点 $q$ 时，在 $G_{T_1}$ 中对应的 $q^{'}$ 点的 $8$ 邻域内进行搜索，如存在边缘点则将其添加到 $G_{T_2}$ 中，然后回到 $G_{T_2}$ 中重新进行搜索；如此重复，直到在 $G_{T_2}$ 和 $G_{T_2}$ 中的搜索都无法继续为止
	· 可以理解成沿着 $G_{T_2}$ 的边缘补 $G_{T_1}$ 中的有效部分
![|475](../../图像处理图4-32.png)
                    （图三十二：利用 LoG 算子和 Canny 算子边缘检测）

2. **边缘闭合**：
· 利用导数算子对图像进行边缘提取后仍存在问题：难以得到一组完整描述一条边缘线的点集
· 在利用边缘检测算子检测图像边缘后，还需要通过边缘闭合的方法将边缘像素连接起来
· 局部边缘连接法的基础是边缘像素之间有一定的相似性
· 用梯度算子对图像进行处理可以得到像素两方面的信息：梯度的幅度和方向
	· 根据边缘像素在这两方面的相似性可把它们连接起来
· 连接过程分为两步：
	· 选择可能位于边缘上的像素点，在该像素点的一个小邻域内查找；若其中某些像素点的梯度值超过某一预定阈值，则把其中具有最大梯度值的点作为候选边缘点
	· 对相邻的候选边缘点，根据事先确定的相似准则来判定是否连接；如果在小邻域内的两个候选点的梯度值和方向差都在一定的范围内，则认为这两点属于同一条边缘，可以连接；连接条件为：
	· 可以理解成选取梯度幅度值相似、梯度方向相近的，而且是最明显的两个点连接
$$\lvert\nabla f(i,j)-\nabla f(m,n)\rvert\leq T$$$$\lvert\phi(i,j)-\phi(m,n)\rvert\leq D$$其中，$\nabla(\cdot)$ 表示梯度模值，$\phi(\cdot)$ 表示梯度方向

3. **Hough 变换**：
· 图像边缘提取很多情况下还需要借助像素点之间的整体关系等空间和结构特性来实现
· 如果图像中要提取的边缘是一条特定形状的曲线（如直线、圆、椭圆、抛物线），这时可以使用 Hough 变换，通过考虑边缘像素的整体关系把该边缘提取出来
· Hough 变换的核心思想：建立一种“点-线”的对偶性关系来检测图像中存在的具有特定形状的物体
· Hough 变换使得图像在变换前为图像空间、变换后为参数空间，通过对参数空间上的参数分布情况的分析，来获取图像空间中对已知形状曲线的检测

· 1962 年：发明者 Paul Hough 在 1962 年获得美国专利，被命名为 Method and Means for Recognizing Complex Patterns（用于识别复杂图案的方法和手段）
· 1972 年由 Richard Duda 和 Peter Hart 改进，称为“广义霍夫变换$[GHT]$”（Use of the Hough Transformation to Detect Lines and Curves in Pictures）
· 1981 年在 Dana H. Ballard 的计算机视觉社区中出现一篇文章名为 Generalizing the Hough transform to detect arbitrary shapes，从而推广开来

· 在图像空间中的直线可以表示为：$$y=kx+q$$$(x,y)$ 为图像上的像素，$k$ 为直线斜率，$q$ 为直线截距，当直线接近垂直时，其斜率 $k$ 可能趋于无穷大
· *性质一*：如果点 $(x_1,y_1)$ 和 $(x_2,y_2)$ 共线，那么这两点在参数 $k-q$ 平面上的直线将有一个交点，具有相同的 $k$ 和 $q$：
![|525](../../图像处理图4-33.png)
                   （图三十三：共线的两点在 $kq$ 平面上直线有一个交点）
· *性质二*：在参数 $k-q$ 平面上相交直线最多的点，对应的 $x-y$ 平面上就是直线方程的解：
![|525](../../图像处理图4-34.png)
                   （图三十四：笛卡尔坐标系的共线和霍夫空间的共点映射）
· 如果是两条直线的情况，选择由尽可能多直线汇成的点：
![|525](../../图像处理图4-35.png)
               （图三十五：笛卡尔空间两条直线，在霍夫空间映射为多直线汇成的点）
· 当直线接近垂直时，其斜率 $k$ 可能趋于无穷大，为避免这种情况出现，一般把直线方程用极坐标形式表示
· 设坐标原点到直线的垂直距离为 $\rho$，直线法线与 $x$ 轴的夹角为 $\theta$，则这条直线可唯一表示为：$$\rho=x\cos{\theta}+y\sin{\theta}$$
· 若 $(x_i,y_i)$ 为图像空间中的一个点，则通过该点的直线均满足$$\rho=x_i\cos{\theta}+y_i\sin{\theta}=(x_i^2+y_i^2)^{\frac{1}{2}}\sin{(\theta+\gamma)}$$式中，$\gamma=\arctan{\frac{x_i}{y_i}}$
![|425](../../图像处理图4-36.png)
                   （图三十六：为了避免斜率无穷大的情况采用极坐标表示法）
![|525](../../图像处理图4-37.png)
                        （图三十七：极坐标系到霍夫空间的映射）
· 根据以 $x$ 和 $y$ 为坐标的图像空间和以 $\rho$ 和 $\theta$ 为坐标的参数空间，可以得到如下对应关系：
1) 图像空间中的一条经过 $(x,y)$ 的直线在参数空间中映射为一个点 $(\rho,\theta)$
2) 图像空间中的一个点 $(x,y)$ 映射为参数空间中的一条正弦曲线
3) 图像空间中的一条直线上的多个共线点映射为参数空间中相交于一点的多条正弦曲线
· 要检测图像空间中的直线，就转换为检测参数空间中正弦曲线相交最多的那个<font color="#ffc000">峰值点</font>，这就是 Hough 变换检测直线的原理

· Hough 变换的具体实现：
1) 将参数空间按 $\rho$ 和 $\theta$ 量化为许多小格
2) 对于每一个边缘点 $(x_i,y_i)$ 将其映射到参数空间并计算出 $\rho$、$\theta$
3) 计算结果落在参数空间上的某个小格中，将该小格的计数单元值加 $1$
4) 当全部边缘点映射完成后，对计数单元进行检测
5) 若只检测一条直线，则根据参数空间上最大计数值单元所对应的点就可以确定图像空间上的直线
6) 若检测的是 $N$ 条直线，则计数值最大的前 $N$ 个计数单元分别对应这 $N$ 条直线的参数
![|425](../../图像处理图4-38.png)
                           （图三十八：Hough 变换的具体实现）
· 霍夫变换空间上的点出现的次数越多，说明源图像空间上对应的这条直线上的点最多，这个边缘越明显
![|425](../../图像处理图4-39.png)
                          （图三十九：用 Hough 变换检测直线）

· <font color="#ffdd44">图像分割的分类</font>：
![|450](../../图像处理图4-40.png)
                               （图四十：图像分割的分类）

###### · 阈值分割方法：

1. **原理和分类**：
· 根据图像分割的定义，同一个分割区的像素灰度之间具有相似的属性，而不同分割区之间具有较大的差异
· 若目标物与背景、不同目标物之间在像素值、像素周围区域性质等方面具有明显的差别，则可以使用阈值分割方法来进行图像分割
· 利用图像中要提取的目标与背景在灰度特性上的差异，把图像视为具有不同灰度级的区域的组合
· 选取一个或多个合适的阈值对图像中每一个像素点进行划分，以确定这些像素应该属于目标还是背景区域，并最终生成分割后的图像

· 阈值分割的流程中，最重要最关键的是如何选取最合适的阈值
（1）全局阈值分割方法，仅根据图像的灰度信息来选取阈值
	1. 灰度直方图双峰法：变成二值图像
	2. 最大类间方差法：$\sigma_B^2=P_1P_2(\mu_1-\mu_2)^2$
	3. 迭代阈值法：$T_0=\frac{L_{low}+L_{high}}{2}$，$T_i=\frac{\mu_1+\mu_2}{2}$
	4. 最大熵方法：$E_1=-\Sigma_{i=0}^{T}\frac{p_i}{P_1}\ln{(\frac{p_i}{P_1})}$，$E_2=-\Sigma_{T+1}^{L-1}\frac{p_i}{P_2}\ln{(\frac{p_i}{P_2})}$
（2）局部阈值分割方法，根据像素的灰度信息和像素周围局部区域性质来选取阈值

2. **全局阈值分割**：
	1. <font color="#00ffb0">灰度直方图双峰法</font>：
		· 灰度直方图双峰法是直接从图像的灰度分布直方图上来确定阈值
		· 直方图双峰法对于目标和背景有很大灰度差异的图像能实现简单而有效地分割
	· 直方图谷点的选取可借助求曲线极小值的方法，需要注意的是，直方图双峰法并不适用于单峰或多峰直方图的图像，而在图像结构比较复杂的情况下，直方图双峰法常常会导致阈值选取失败
	· 接近于峰值点的全部取峰值处的灰度，得到结果是一个二值图像
![|500](../../图像处理图4-41.png)
                    （图四十一：用灰度直方图双峰法实现全局阈值分割）
2. ……
	2. <font color="#00ffb0">最大类间方差法</font>：
		· 从统计意义上讲，*方差是表征数据分布不均衡性的统计量*，它反映了数据的分散程度
		· 用方差来衡量目标和背景之间的差别，并将使目标和背景两类的类间方差最大的灰度级作为最佳阈值
		· 背景和目标之间的类间方差越大，说明构成图像背景和目标的差别越大，当部分目标被错分为背景或部分背景被错分为目标时两部分的差别都会变小；因此，*使类间方差最大的分割意味着错分概率最小*
	· 根据上述设计思想，该方法的具体步骤如下：
	（1）计算图像中所有灰度级的分布概率：设一幅大小为 $M*N$，灰度级为 $L$ 的图像，如果图像中灰度级为 $I$ 的像素个数为 $N_i$，则灰度级 $I$ 的分布概率为：$$p_i=\frac{N_i}{M\times N}$$
	（2）给定初始阈值 $T$ 把图像分为 $C_1$ 和 $C_2$ 两类，计算 $C_1$ 类和 $C_2$ 类的分布概率 $P_1$ 和 $P_2$：$$P_1=\Sigma_{i=0}^T\ p_i,\ \ \ \ P_2=1-P_1$$
	（3）分别计算 $C_1$ 和 $C_2$ 两类的类内灰度均值 $\mu_1$、$\mu_2$，以及图像的总体灰度均值 $\mu$：$$\mu_1=\Sigma_{i=0}^T\ iP(i\vert C_1)=\Sigma_{i=0}^T\ i\frac{p_i}{P_1}=\frac{\mu(T)}{P_1}$$$$\mu_2=\Sigma_{i=T+1}^{L-1}\ iP(i\vert C_2)=\Sigma_{i=T=1}^{L-1}\ i\frac{p_i}{P_2}=\frac{\mu-\mu_1}{P_2}$$$$\mu=\Sigma_{i=0}^{L-1}\ ip_i$$式中：$$\mu(T)=\Sigma_{i=0}^T\ ip_i$$
	（4）计算图像的类间方差：$$\sigma_{B}^2=P_1(\mu_1-\mu)^2+P_2(\mu_2-\mu)^2=P_1P_2(\mu_1-\mu_2)^2$$
	（5）选择最佳阈值 $T_{opt}$ 使类间方差最大：$$T_{opt}=\arg_{(0\leq T\leq L-1)}{\max{\sigma_B^2}}$$
· 最大类间方差法对于目标与背景的面积相差不大的图像能够较好地实现图像分割
· 最大类间方差法的不足：
	· 当图像中的目标与背景的面积相差很大时，分割效果可能不佳
	· 目标与背景的灰度有较大的重叠时也有可能不能准确地将目标与背景分开
![|500](../../图像处理图4-42.png)
                      （图四十二：用最大类间方差法实现全局阈值分割）

2. ……
	3. <font color="#00ffb0">迭代阈值法</font>：
		· 迭代阈值法是通过多次迭代的方法计算图像分割的最佳阈值
		· 迭代阈值法具有一定的自适应性
	· 迭代阈值法设计思想：
		· 先选择一个近似阈值作为最优分割阈值的初始值
		· 借助该初始值把图像分为两类，然后基于这两类的平均灰度计算新的分割阈值
		· 这一过程重复进行，从而不断对分割阈值进行修正
· 迭代阈值法实现：
1) 给定初始阈值 $T_0$，例如可以求出图像中的最大灰度值 $t_{L-1}$ 和最小灰度值 $t_0$，并令：$$T_0=\frac{t_0+t_{L-1}}{2}$$
2) 根据当前阈值把图像分为 $C_1$ 和 $C_2$ 两类，计算 $C_1$ 和 $C_2$ 类的平均灰度 $u_1$ 和 $u_2$
3) 求出新的阈值：$$T^{k+1}=\frac{u_1+u_2}{2}$$
4) 如果 $T^{k+1}=T^k$，则迭代结束，否则 $k\leftarrow k+1$，转到第 (2) 不继续迭代

2. ……
	4. <font color="#00ffb0">最大熵方法</font>：
		· 熵是信息论中对数据中所包含信息量大小的度量
		· 由熵的定义可知，信息源的不确定性大，信息熵大；熵取最大值时，就表明获得的信息量为最大
		· 最大熵方法的设计思想是，选择适当的阈值将图像分为目标和背景两类，两类的平均熵之和为最大时，可从图像中获得最大信息量，以此来确定最佳阈值
· 最大熵方法实现步骤：
1) 计算出图像中所有灰度级的分布概率，设一幅大小为 $M\times N$，灰度级为 $L$ 的图像，如果图像中灰度级为i的像素个数为 $N_i$，则灰度级 $i$ 的概率为：$$p_i=\frac{N_i}{M\times N}$$
2) 给定初始阈值 $T$ 把图像分为 $C_1$ 和 $C_2$ 两类，计算图像目标区域的熵和图像背景区域的熵：$$E_1=-\Sigma_{i=0}^T(\frac{p_i}{p_T})\cdot\ln(\frac{p_i}{p_T})$$$$E_2=-\Sigma_{i=T+1}^{L-1}(\frac{p_i}{1-p_T})\cdot\ln{(\frac{p_i}{1-p_T})}$$式中：$$p_T=\Sigma_{i=0}^T\ p_i$$
3) 最大熵法的最佳阈值公式为：$$T^{opt}=\arg{\max{[E_1(T)+E_2(T)]}}$$
· 遍历图像的灰度级，求得使目标区域和背景区域平均熵的和最大的灰度级，即为最佳分割阈值
![|400](../../图像处理图4-43.png)
         （图四十三：求得使目标区域和背景区域平均熵的和最大的灰度级，即为最佳分割阈值）

3. **局部阈值分割**：
· 全局阈值方法采用单一阈值，对于较为简单的图像（即目标与背景比较容易区分）简单且有效；对于较为复杂的图像，则往往会产生一些问题
· 全局阈值法只考虑灰度信息，不同局部区域的像素灰度特性存在不同
![|525](../../图像处理图4-44.png)
                （图四十四：全局阈值法不考虑局部区域像素灰度特性不同的缺点）

· 局部阈值分割的基本思想：首先将图像分解成一系列的子图像，这些子图像相互间可以有一定的重叠，也可以只相邻；在每个子块上采用任何一种固定阈值方法选择合适的阈值进行分割；如果子图像块的尺寸划分的比较合适，则在每个子块上，由光照不均或阴影造成的影响就比较小，甚至可以忽略不计；这时，对每个子图像块选取合适的阈值进行分割就可以达到比较理想的分割效果
![|525](../../图像处理图4-45.png)
                          （图四十五：局部阈值分割的基本思想）

###### · 区域分割方法：
· 基于区域的图像分割方法是利用同一区域内特征的相似性，将相似的区域合并，而把不相似的区域分开，最终把图像划分成一系列有意义区域的处理方法
· 这类方法的核心，就是如何对区域的特性进行恰当的描述，以及如何根据该特性进行区域划分；基于区域的图像分割方法在有噪声的图像中一般会有更好的效果

· 区域生长法：
	· 简单生长法：点—点
	· 质心生长法：区域—点
	· 区域生长法：区域—区域
· 分裂合并：按方差阈值分裂，按均值阈值合并

1. **区域生长**：
· 基本思想是将具有相似性质的像素集合起来构成区域
· 该方法需要先在每个待分割的区域中选取一个种子点，接着依次将种子像素和周围邻域中与种子像素有相同或相似性质的像素（根据某种事先确定的生长或相似准则来判定）归并到种子像素所在的区域中，然后将这些新像素当作新的种子继续合并的过程，直到再没有满足条件的像素可被包括进来为止；这样一个区域就生长成了
· 区域内像素的相似性度量可以包括平均灰度值、纹理、颜色等信息
· 进行区域生长时，要解决三个问题：
1) 确定要分隔的区域数目，并在每个区域内选择或确定一个能正确代表该区域灰度取值的种子点；选取的种子点原则上是待提取区域的有代表性的点；可是单个像素，也可是包括若干个像素的子区域；种子点可以随着区域的生长而变化，也可以设定为一个固定的数值；通常，种子点的选取要借助于具体问题的特点进行
2) 确定有意义的特征和生长准则；生长准则是确定与种子点相似程度的度量，也是区域生长（或相邻小区域合并）的条件；生长准则多采用与种子点的距离度量，可以是像素方式也可以是区域方式；生长准则的选取不仅依赖于具体问题本身，也和所用图像数据的种类有关；例如，当所处理图像是彩色图像时，仅用灰度准则分割效果可能就会受到影响；另外，在确定生长准则时还需要考虑像素间的连通性和邻近性，否则有时可能出现无意义的分割结果
3) *确定生长停止准则*：判定生长停止的阈值可以是确定的值，也可以是随生长而变化的值；一般生长过程在进行到再没有满足生长准则需要的像素点时停止；但常用的基于灰度、纹理、彩色的准则大都基于图像中的局部性质，并没有充分考虑生长的历史；因此，渐变区域进行生长时的停止判断非常重要；一般需要结合生长准则来进行合理的设定
· 根据所用邻域方式和生长准则的不同，区域生长法可以分为多种类型
· 这里仅介绍基本的三类：*简单生长*、*质心生长*和*区域生长*

1. ……
	1. <font color="#00ffb0">简单生长法</font>：
		· 按照事先确定的生长准则，生长点（种子点为第一个生长点）接收其邻域内具有相同属性的点，接收后的像素点可以作为新的生长点；重复此过程，直到不能生长为止，此时区域生成：$$\lvert f(x,y)-f(m,n)\rvert\leq T$$式中，$f(m,n)$ 表示生长点 $(m,n)$ 的某种属性值，如灰度；$f(x,y)$ 表示 $(m,n)$ 的邻域点 $(x,y)$ 的属性值；$T$ 表示相似性阈值
	2. <font color="#00ffb0">质心生长法</font>：
		· 质心生长法考虑了已生成区域的整体信息，其生长准则：$$\lvert f(x,y)-\overline{f(m,n)}\rvert\leq T$$式中，$\overline{f(m,n)}$ 是已生长区域内所有像素的灰度平均值（质心），这样就可以克服简单生长法中过分依赖种子点的缺陷
	3. <font color="#00ffb0">区域生长法</font>：
		· 区域生长法是通过生长准则将相邻两个性质相似的区域合并起来，其生长准则如式所示：$$\lvert\overline{f_i}-\overline{f_j}\rvert\leq T$$式中，$\overline{f_i}$ 和 $\overline{f_j}$ 分别为相邻的第 $i$ 区域和第 $j$ 区域的灰度平均值
![|450](../../图像处理图4-46.png)
                            （图四十六：区域生长法的示例 Ⅰ）
![|450](../../图像处理图4-47.png)
                            （图四十七：区域生长法的示例 Ⅱ）

2. **分裂合并**：
· 区域分裂合并法无需预先指定种子点，它按某种一致性准则分裂或者合并区域
· 区域分裂合并算法的基本思想是将输入图像分成多个子区域，然后对相邻的子区域根据某种判断准则迭代地进行合并；区域分裂合并方法可以先进行分裂运算，再进行合并运算；也可以分裂和合并运算同时进行
· 具体实现时，先确定一个分裂准则和一个相似性准则；利用分裂准则先把整个图像分为若干个子区域再利用分裂准则对每个子区域进行检测，当某个子区域的特征不一致时就将该子区域分裂成若干个更小的子区域
· 这一过程重复进行，当分裂到不能再分的情况时，分裂结束
· 查找相邻子区域有没有相似的特征，当相邻的子区域满足相似性准则时就将它们进行合并，直至所有区域不再满足分裂合并的条件为止
![|450](../../图像处理图4-48.png)
                           （图四十八：分裂合并的算法示例）

· *区域生长和区域分裂合并算法从原理而言是互相促进相辅相成的*
· 区域分裂到极致就可以分裂为单一像素点，然后按照一定的测量准则进行合并，在一定程度上可以认为是单一像素点的区域生长方法
· 而区域生长法比区域分裂合并法缩短了分裂的过程；区域分裂合并的方法通过反复拆分和聚合以实现分割，它可以在较大的一个相似区域基础上再进行相似合并，而区域生长通常需要从单一像素点出发进行生长（合并）
· 分裂合并算法的优点是不需要预先指定种子点，对于分割复杂的场景图像比较有效；而缺点是分裂合并算法可能会使分割区域的边界被破坏（边缘点在大片区域中，不会很大地影响方差，接受后导致边缘被淹没）


### 叁  数字图像处理公式与算法要点：

###### 1. 亮度对比度和相对对比度：
$$亮度对比度：C=\frac{I_{max}}{I_{min}}$$$$相对对比度：C=\frac{I_{物体}-I_{背景}}{I_{背景}}$$

###### 2. 图像存储需要的比特数：
$$Bits(Image)=M\times N\times k,\ \ \ \ L=2^k,\ \ \ L为图像灰度级数,\ \ \ k为颜色深度$$

###### 3. 像素空间关系：
· $4$ - 邻域：$N_4(p)$
· 对角邻域：$N_D(p)$
· $8$ - 邻域：$N_8(p)$
· $4$ - 邻接，$8$ - 邻接，$m$ - 邻接（混合邻接）
· 连通分量与连通集，连通与连接
· 距离：
$$欧氏距离：D_E=[(x-s)^2+(y-t)^2]^{\frac{1}{2}}$$$$城区距离：D_4=\lvert x-s\rvert+\lvert y-t\rvert$$$$棋盘距离：D_8=\max{(\lvert x-s\rvert,\ \lvert y-t\rvert)}$$
· 混合距离 $D_m$：混合邻域中走出的路线长度

###### 4. 图像几何变换：
$$缩放变换：\begin{bmatrix}S_x&0&0\\ 0&S_y&0\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}S_x\cdot x\\ S_y\cdot y\\ 1\end{bmatrix}$$$$剪切变换：\begin{bmatrix}1&a&0\\ b&1&0\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}x+ay\\ bx+y\\ 1\end{bmatrix}$$$$逆时针旋转变换：\begin{bmatrix}\cos{\theta}&-\sin{\theta}&0\\ \sin{\theta}&\cos{\theta}&0\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}x\cos{\theta}-y\sin{\theta}\\ x\sin{\theta}+y\cos{\theta}\\ 1\end{bmatrix}$$$$平移变换：\begin{bmatrix}1&0&t_x\\ 0&1&t_y\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}x+t_x\\ y+t_y\\ 1\end{bmatrix}$$$$镜像变换：\begin{bmatrix}-1&0&0\\ 0&1&0\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}-x\\ y\\ 1\end{bmatrix},\ \ \ \ \begin{bmatrix}1&0&0\\ 0&-1&0\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}x\\ -y\\ 1\end{bmatrix}$$$$当对称轴是\ x=w，则\ x^{'}+x=2w，对称变换：\begin{bmatrix}-1&0&2w\\ 0&1&0\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}-x+2w\\ y\\ 1\end{bmatrix}$$$$当对称轴是\ y=h，则\ x^{'}+x=2h，对称变换：\begin{bmatrix}1&0&0\\ 0&-1&2h\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}=\begin{bmatrix}x\\ -y+2h\\ 1\end{bmatrix}$$
· 正交投影：线性变换，无“近大远小”：$$1.\ 先将图像中心平移到原点：\begin{bmatrix}1&0&0&-\frac{r+l}{2}\\ 0&1&0&-\frac{t+b}{2}\\ 0&0&1&-\frac{n+f}{2}\\ 0&0&0&1\end{bmatrix}$$$$2.\ 将图像缩放到目标大小：\begin{bmatrix}\frac{K}{r-l}&0&0&-\frac{r+l}{r-l}\\ 0&\frac{K}{t-b}&0&-\frac{t+b}{t-b}\\ 0&0&\frac{K}{n-f}&-\frac{n+f}{n-f}\\ 0&0&0&1\end{bmatrix}$$
· 透视投影：先非线性挤压，再正交投影：$$z\ 轴方向挤压矩阵：\begin{bmatrix}\frac{n}{z}&0&0&0\\ 0&\frac{n}{z}&0&0\\ 0&0&\frac{n}{z}&0\\ 0&0&0&1\end{bmatrix},\ \ \ \ n\ 为挤压目标\ z\ 轴分量，即近平面距离$$
· 反变换：矩阵求逆
· 复合变换：矩阵乘积：
$$绕任意点旋转：\begin{bmatrix}1&0&x_0\\ 0&1&y_0\\ 0&0&1\end{bmatrix}\begin{bmatrix}\cos{\theta}&-\sin{\theta}&0\\ \sin{\theta}&\cos{\theta}&0\\ 0&0&1\end{bmatrix}\begin{bmatrix}1&0&-x_0\\ 0&1&-y_0\\ 0&0&1\end{bmatrix}\begin{bmatrix}x\\ y\\ 1\end{bmatrix}$$$$=\begin{bmatrix}(x-x_0)\cos{\theta}-(y-y_0)\sin{\theta}+x_0\\ (x-x_0)\sin{\theta}+(y-y_0)\cos{\theta}+y_0\\ 1\end{bmatrix}$$
· 自由度（$x-y$ 平面为例）：
	· 平移变换自由度为 $2$
	· 线性变换自由度为 $4$
	· 仿射变换（线性加平移）自由度为 $6$
	· 投影变换自由度为 $8$

###### 5. 灰度映射：
$$图像反转：t=255-k$$$$对数变换：t=C\log{(k+1)},\ \ \ \ C=\frac{L-1}{\log{L}}$$$$幂次变换：t=Ck^\gamma,\ \ \ \ C=\frac{1}{(L-1)^{\gamma-1}}$$

###### 6. 直方图均衡化：
$$t_k=round{(F(t_k))},\ \ \ \ F(t_k)\ 为累积分布函数在\ t_k\ 的值$$

###### 7. 直方图规定化：
· 单映射规则（SML）：累积分布“点对点”
· 组映射规则（GML）：累积分布“段对段”

###### 8. 离散卷积的边缘效应公式：
· 卷积核的尺寸往往是奇数，其半径大小为：$r=\frac{n-1}{2}$
$$输出尺寸：O=\frac{I-F+P_{start}+P_{end}}{S},\ \ \ \ S\ 为步长$$

###### 9. 卷积公式：
$$一维连续卷积：r(t)=\int_{-\infty}^{\infty}e(\tau)\ h(t-\tau)\ d\tau$$$$一维离散卷积：h(i)=f(i)\otimes g(i)=\Sigma_{u=0}^{m-1}\ f(u)\ g(i-u)$$$$二维连续卷积：h(x,y)=f(x,y)\otimes g(x,y)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\ f(u,v)\ g(x-u,y-v)\ du\ dv$$$$二维离散卷积：h(i,j)=f(i,j)\otimes g(i,j)=\Sigma_{m=-\infty}^{\infty}\Sigma_{n=-\infty}^{\infty}\ f(m,n)\ g(i-m,j-n)$$

###### 10. 线性平滑滤波：

1. <font color="#00ffb0">均值滤波</font>：
· 常用卷积核：
$$\frac{1}{9}\times\begin{bmatrix}1&1&1\\ 1&1&1\\ 1&1&1\end{bmatrix},\ \ \ \ \frac{1}{4}\times\begin{bmatrix}0&1&0\\ 1&0&1\\ 0&1&0\end{bmatrix},\ \ \ \ \frac{1}{8}\times\begin{bmatrix}1&1&1\\ 1&0&1\\ 1&1&1\end{bmatrix}$$

2. <font color="#00ffb0">选择平均法</font>：
· 阈值法：邻域灰度求均值，如果中心点和邻域均值差距大于阈值，认为是噪声，用邻域均值代替，否则保留
· 半邻域法：将邻域 $8$ 个点灰度值从小打大排序，取前三点个均值为 $A$，后五个点均值为 $B$，如果 $A$ 和 $B$ 的均值大于阈值，认为这是边界，中间值取中间值和后五个点这 $6$ 个点的均值；否则，取 $8$ 邻域均值

3. <font color="#00ffb0">加权平均法</font>：
· 高斯滤波模板：$$e^{-\frac{x^2+y^2}{2\sigma^2}}$$

4. <font color="#00ffb0">维纳滤波</font>：
$$[g(x,y)-\mu]\sigma^2=[f(x,y)-\mu](\sigma^2-\nu^2),\ \ \ \ \mu和\sigma是邻域均值和方差，\nu是全图方差$$

| 滤波类型      | 原理                              | 优点                          | 缺点                      | 关键参数                                            | 应用实例                  |
| --------- | ------------------------------- | --------------------------- | ----------------------- | ----------------------------------------------- | --------------------- |
| **均值滤波**  | 对每个像素周围邻域的像素值进行平均               | 算法简单，计算速度快，易于实现             | 会造成图像模糊，尤其是使用较大核时       | 核大小（例如 `ksize`）                                 | 图像平滑、一般图像噪声去除         |
| **选择平均法** | 仅对灰度相近或满足阈值条件的像素进行平均            | 通过避免与噪声像素的平均，减少边缘模糊         | 由于需要阈值判断，计算量可能较大        | 阈值（T）、邻域大小（M）                                   | 去除噪声且保留边缘，尤其适合边缘检测    |
| **加权平均法** | 使用加权平均，靠近中心像素的像素权重较大            | 比均值滤波能更好地保持图像的边缘            | 需要仔细选择权重（例如高斯权重）        | 核大小、权重（例如高斯核）、`sigma`                           | 保留边缘的平滑，常用于高斯滤波       |
| **高斯滤波**  | 使用高斯核进行加权平均，像素权重依据与中心的距离而变化     | 能平滑图像并且保持边缘，计算效率较高          | 如果 `sigma` 值过大，可能导致边缘模糊 | 核大小、标准差（`sigma`）                                | 去噪、去阴影、细节保留等图像处理      |
| **维纳滤波**  | 基于最小均方误差准则，使用图像的局部均值和方差来调整滤波器输出 | 自适应滤波，可以根据局部图像内容调整滤波效果，保持细节 | 计算复杂，需要估计局部方差，对噪声类型有依赖  | 邻域大小（`m`, `n`）、图像方差、局部均值、标准差（`sigma^2`, `nu^2`） | 去噪、图像恢复，尤其适用于噪声较复杂的图像 |

###### 11. 非线性平滑滤波：

1. <font color="#00ffb0">中值滤波</font>：一维中值滤波，二维中值滤波，取模板内的灰度中值
2. <font color="#00ffb0">加权中值滤波</font>：模板上带有权重，表示对一个像素灰度值的重复读取次数
3. <font color="#00ffb0">其他排序统计滤波</font>：最大值滤波器，最小值滤波器，中点值滤波器（最大最小的中间值）

| 滤波器类型      | 原理                       | 优点                        | 适用噪声              | 输出示例              |
| ---------- | ------------------------ | ------------------------- | ----------------- | ----------------- |
| **一维中值滤波** | 使用滑动模板对信号序列中的每个点计算邻域值的中值 | 消除孤立脉冲噪声，不影响理想边缘          | 孤立脉冲噪声（如椒盐噪声）     | 以中值代替模板中心点的值      |
| **二维中值滤波** | 对每个像素，计算其邻域内像素的中值并替代原值   | 去噪效果好，能有效消除椒盐噪声且不影响边缘     | 椒盐噪声              | 替换模板中心位置的像素值为邻域中值 |
| **加权中值滤波** | 在中值计算时使用不同权重模板，以权重计算中值   | 去噪效果更好，能较好保留图像结构细节        | 各种类型噪声（如椒盐噪声）     | 按照权重模板排序后，取中间值    |
| **最大值滤波器** | 选取邻域内像素的最大值              | 强调图像中最亮的部分，抑制较暗的噪声        | 提高对图像亮点的响应，减弱暗点噪声 | 输出邻域内的最大值         |
| **最小值滤波器** | 选取邻域内像素的最小值              | 强调图像中最暗的部分，抑制较亮的噪声        | 减弱亮点噪声，突出图像暗点     | 输出邻域内的最小值         |
| **中点滤波器**  | 选取邻域内像素的最大值和最小值的平均值      | 结合了排序滤波器和均值滤波器的优点，对多种噪声有效 | 高斯噪声、均匀噪声         | 输出最大值和最小值的平均值     |

###### 12. 锐化滤波：

1. <font color="#ffc000">梯度法</font>：一阶
	1. 水平垂直梯度法：
	$$水平差分：G_Y=f(x,y)-f(x,y+1)，垂直差分：G_X=f(x,y)-f(x+1,y)$$$$水平差分模板：\begin{bmatrix}1&-1\\ 0&0\end{bmatrix},\ \ \ \ 垂直差分模板：\begin{bmatrix}1&0\\ -1&0\end{bmatrix}$$
	2. 罗伯特差分法：
	$$左下右上差分：G_X=f(x+1,y)-f(x,y+1)$$$$左上右下差分：G_Y=f(x,y)-f(x+1,y+1)$$$$差分模板：\begin{bmatrix}0&-1\\ 1&0\end{bmatrix},\ \ \ \ \begin{bmatrix}1&0\\ 0&-1\end{bmatrix},$$
	3. 改进方法：
	· 阈值法：当梯度大于阈值的时候才采用梯度值给像素赋值，避免梯度过小时输出的图像过暗

2. <font color="#ffcb00">Prewitt 卷积算子</font>：一阶$$H_H=\begin{bmatrix}1&0&-1\\ 1&0&-1\\ 1&0&-1\end{bmatrix},\ \ \ \ H_V=\begin{bmatrix}1&1&1\\ 0&0&0\\ -1&-1&-1\end{bmatrix}$$

3. <font color="#ffc000">Sobel 卷积算子</font>：一阶$$H_H=\begin{bmatrix}1&0&-1\\ 2&0&-2\\ 1&0&-1\end{bmatrix},\ \ \ \ H_V=\begin{bmatrix}1&2&1\\ 0&0&0\\ -1&-2&-1\end{bmatrix}$$

4. <font color="#ffc000">拉普拉斯算子</font>：二阶$$\begin{bmatrix}0&1&0\\ 1&-4&1\\ 0&1&0\end{bmatrix}\ \ \ \ \begin{bmatrix}0&-1&0\\ -1&4&-1\\ 0&-1&0\end{bmatrix}\ \ \ \ \begin{bmatrix}1&1&1\\ 1&-8&1\\ 1&1&1\end{bmatrix}\ \ \ \ \begin{bmatrix}-1&-1&-1\\ -1&8&-1\\ -1&-1&-1\end{bmatrix}$$

5. <font color="#ffc000">LOG 算子</font>：二阶
	· 先高斯平滑，再锐化：$$归一化的高斯算子：g(x,y)=\frac{1}{2\pi\sigma^2}e^{-\frac{x^2+y^2}{2\sigma^2}}$$$$\Rightarrow LoG=\nabla^2 g(x,y)=\frac{\partial^2 g}{\partial x^2}+\frac{\partial^2 g}{\partial y^2}=\frac{1}{\pi\sigma^4}(\frac{x^2+y^2}{2\sigma^2}-1)e^{-\frac{x^2+y^2}{2\sigma^2}}$$

6. <font color="#ffc000">DOG 算子（高斯差分算子）</font>：二阶$$DOG=\frac{1}{2\pi\sigma_1^2}e^{-\frac{x^2+y^2}{2\sigma_1^2}}-\frac{1}{2\pi\sigma_2^2}e^{-\frac{x^2+y^2}{2\sigma_2^2}}$$

7. <font color="#ffc000">高通滤波器</font>：$$H_1=\begin{bmatrix}0&-1&0\\ -1&5&-1\\ 0&-1&0\end{bmatrix}\ \ \ \ H_2=\begin{bmatrix}-1&-1&-1\\ -1&9&-1\\ -1&-1&-1\end{bmatrix}\ \ \ \ H_3=\begin{bmatrix}1&-2&1\\ -2&5&-2\\ 1&-2&1\end{bmatrix}$$

8. <font color="#ffc000">掩膜法</font>：原始图像减去低通（平滑）图像得到高通（锐化）图像：$$g(x,y)=\begin{cases}g(x,y),\ \ \ \ g(x,y)\geq T\\ 255,\ \ \ \ \ \ \ \ \ \ g(x,y)\textless T\end{cases}$$


###### 13. 欧拉公式：
$$e^{ix}=\cos{x}+i\sin{x}$$$$\cos{x}=\frac{e^{ix}+e^{-ix}}{2}$$$$\sin{x}=\frac{e^{ix}-e^{-ix}}{2i}=\frac{-i}{2}(e^{ix}-e^{-ix})$$

###### 14. 一维连续傅里叶变换：
$$时域下表示：f(t)=\Sigma_{-\infty}^{\infty}c_ne^{i\frac{2\pi nt}{T}}$$$$频域下表示：c_n=\frac{1}{T}\int_{-\frac{T}{2}}^{\frac{T}{2}}f(t)e^{-i\frac{2\pi nt}{T}}dt$$
· 傅里叶变换：$$F(w)=\frac{1}{2\pi}\int_{-\infty}^{\infty}f(t)e^{-iwt}dt$$
· 傅里叶反变换：$$f(x)=\int_{-\infty}^{\infty}F(w)e^{iwx}dw$$

###### 15. 一维离散傅里叶变换：
$$时域下表示：F(u)=\Sigma_{x=0}^{N-1}f(t)e^{-j\frac{2\pi ut}{N}}$$$$频域下表示：f(x)=\Sigma_{u=0}^{N-1}F(u)e^{j\frac{2\pi ux}{N}}$$

###### 16. 二维连续傅里叶变换：
$$F(u,v)=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f(x,y)\cdot e^{-j2\pi(ux+vy)}\ dxdy$$$$f(x,y)=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}F(u,v)\cdot e^{j2\pi(ux+vy)}\ dudv$$

###### 17. 二维离散傅里叶变换：
$$F(u,v)=\Sigma_{x=0}^{N-1}\Sigma_{y=0}^{N-1}[f(x,y)\cdot e^{-j2\pi\frac{ux+vy}{N}}]$$$$f(x,y)=\frac{1}{N^2}\Sigma_{u=0}^{N-1}\Sigma_{v=0}^{N-1}[F(u,v)\cdot e^{j2\pi\frac{ux+vy}{N}}]$$

###### 18. 傅里叶变换的性质：

1. <font color="#ffc000">线形算子</font>：$$af_1(x,y)+bf_2(x,y)\Leftrightarrow aF_1(u,v)+bF_2(u,v)$$
2. $x$ <font color="#ffc000">和</font> $y$ <font color="#ffc000">可分离性</font>：$$f(x,y)=\frac{1}{N^2}\Sigma_{u=0}^{M-1}[\Sigma_{v=0}^{N-1}F(u,v)e^{j2\pi vy/N}]e^{j2\pi vx/M}$$
3. <font color="#ffc000">加法定理</font>：$$r(u)=f(u)+g(u)\Leftrightarrow R(u)=F(u)+G(u)$$
4. <font color="#ffc000">位移定理</font>：$$频域位移：f(x,y)e^{j2\pi(u_0x/M+v_0y/N)}\Leftrightarrow F(u-u_0,v-v_0)$$$$空间位移：f(x-x_0,y-y_0)\Leftrightarrow F(u,v)e^{-j2\pi(u_0x/M+v_0y/N)}$$
· 把频率坐标系的原点移到中心：$u_0=\frac{M}{2},v_0=\frac{N}{2}$：$$f(x,y)\cdot e^{j2\pi(u_0x/M+v_0y/N)}=f(x,y)\cdot(-1)^{x+y}\Leftrightarrow F(u-\frac{M}{2},v-\frac{N}{2})$$
5. <font color="#ffc000">相似性定理</font>：$$f(ax,by)\Leftrightarrow\frac{1}{\lvert ab\rvert}F(\frac{u}{a},\frac{v}{b})$$
6. <font color="#ffc000">周期性</font>：$f(x,y)$ 和 $F(u,v)$ 的周期都是 $N$
7. <font color="#ffc000">原点周期对称性和旋转不变性</font>

###### 19. 频率域中滤波的步骤：

1. 中心化并傅里叶变换得到 $F(u,v)$
$$f(x,y)(-1)^{x+y}\Leftrightarrow F(u-\frac{M}{2},v-\frac{N}{2})$$
2. 滤波：
$$G(u,v)=H(u,v)F(u,v)$$
3. 反变换：
$$G(u,v)\Rightarrow g(x,y)$$
4. 反中心化：
$$g^{'}(x,y)=g(x,y)\cdot(-1)^{x+y}$$

###### 20. 二维离散余弦变换：
$$F(u,v)=a(u)a(v)\Sigma_{x=0}^{N-1}\Sigma_{y=0}^{N-1}f(x,y)\cos{\frac{(2x+1)u\pi}{2N}}\cos{\frac{(2y+1)v\pi}{2N}},\ \ u,v=0,1,\ldots,N-1$$$$归一化加权系数：a(u)=\begin{cases}\sqrt{\frac{1}{N}},\ \ u=0\\ \sqrt{\frac{2}{N}},\ \ u=1,2,\ldots,N-1\end{cases}$$

###### 21. 频域图像增强：

1. 低通滤波：
	1. 理想低通滤波器：$$H(u,v)=\begin{cases}1,\ \ D(u,v)\leq D_0\\ 0,\ \ D(u,v)\textgreater D_0\end{cases}$$
	2. 巴特沃斯低通滤波器：$$H(u,v)=\frac{1}{1+[\frac{D(u,v)}{D_0}]^{2n}}$$$$H(u,v)=\frac{1}{1+(\sqrt{2}-1)[\frac{D(u,v)}{D_0}]^{2n}}$$
	3. 指数低通滤波器：$$H(u,v)=e^{-[\frac{D(u,v)}{D_0}]^n}$$$$H(u,v)=e^{-0.347[\frac{D(u,v)}{D_0}]^n}$$
	4. 梯形低通滤波器：$$H(u,v)=\begin{cases}\ \ \ \ \ \ 1,\ \ \ \ \ \ \ \ \ \ \ \ \ \ D(u,v)\textless D_0\\ \frac{D(u,v)-D_1}{D_0-D_1},\ \ \ \ D_0\leq D(u,v)\leq D_1\\ \ \ \ \ \ \ 0,\ \ \ \ \ \ \ \ \ \ \ \ \ \ D(u,v)\textgreater D_1\end{cases}$$
	5. 高斯低通滤波器：$$H(u,v)=e^{-\frac{D^2(u,v)}{2D_0^2}}$$$$H(u,v)=e^{-0.347\frac{D^2(u,v)}{2D_0^2}}$$
2. 高通滤波器：
	1. 理想高通滤波器：$$H(u,v)=\begin{cases}1,\ \ D(u,v)\textgreater D_0\\ 0,\ \ D(u,v)\leq D_0\end{cases}$$
	2. 巴特沃斯高通滤波器：$$H(u,v)=\frac{1}{1+[\frac{D_0}{D(u,v)}]^{2n}}$$$$H(u,v)=\frac{1}{1+(\sqrt{2}-1)[\frac{D_0}{D(u,v)}]^{2n}}$$
	3. 指数高通滤波器：$$H(u,v)=e^{-[\frac{D_0}{D(u,v)}]^n}$$$$H(u,v)=1-e^{-[\frac{D(u,v)}{D_0}]^n}$$$$H(u,v)=e^{-0.347[\frac{D_0}{D(u,v)}]^n}$$
	4. 梯形高通滤波器：$$H(u,v)=1-H_{lp}(u,v)=\begin{cases}\ \ \ \ \ \ 0,\ \ \ \ \ \ \ \ \ \ \ \ \ \ D(u,v)\textless D_1\\ \frac{D(u,v)-D_1}{D_0-D_1},\ \ \ \ D_0\leq D(u,v)\leq D_1\\ \ \ \ \ \ \ 1,\ \ \ \ \ \ \ \ \ \ \ \ \ \ D(u,v)\textgreater D_0\end{cases}$$
	5. 高斯高通滤波器：$$H(u,v)=1-e^{-\frac{D^2(u,v)}{2D_0^2}}$$$$H(u,v)=1-e^{-0.347\frac{D^2(u,v)}{2D_0^2}}$$
3. 高频增强滤波器：对高通滤波器的转移函数加一个常数以将一些低频分量加回去

###### 22. 信息公式：
$$信息量：I(x)=-\log_2p(x)$$$$信息熵：H=-\Sigma_{i=1}^n\ p_i(x)\log_2p_i(x)$$$$平均编码长度：R=\Sigma_{i=1}^n\ \beta_i\ p_i(x),\ \ \ \ \beta_i\ 为第\ i\ 个码字\ x_i\ 的编码长度$$$$压缩比：C=\frac{R_{src}}{R_{des}}$$$$编码效率：\eta=\frac{H}{R}$$$$香农第一定理：\lim_{n\to\infty}{[\frac{L_{avg,n}}{n}]}=H，无损压缩的极限是信息熵$$$$均方信号比：SNR_{ms}=\frac{\Sigma_{x=0}^{M-1}\Sigma_{y=0}^{N-1}\hat{f}(x,y)^2}{\Sigma_{x=0}^{M-1}\Sigma_{y=0}^{N-1}[\hat{f}(x,y)-f(x,y)]^2}$$

###### 23. 基本无损编码：

1. 哈夫曼编码
2. 数值编码
3. 行程编码
4. LZW 编码

###### 24. 基本预测编码：

1. 有损预测编码
2. 无损预测编码：取前两个像素灰度均值，后一个像素灰度值与这个均值作差，以此类推

###### 25. 基于边缘的图像分割：

· 边缘检测—>边缘闭合—>Hough 变换
· 边缘检测：Canny 边缘检测算子平滑—>梯度锐化—>非极大值抑制—>双阈值边缘保留
· 边缘闭合：梯度幅度相近，梯度方向相似，且明显的两个点连接
· Hough 变换：通过 Hough 空间上 $k-q$ 直线或 $\rho-\theta$ 正弦曲线交点检测源图像空间上的直线

###### 26. 基于阈值的图像分割：

（1）全局阈值分割方法，仅根据图像的灰度信息来选取阈值
	1. 灰度直方图双峰法：变成二值图像
	2. 最大类间方差法：$\sigma_B^2=P_1P_2(\mu_1-\mu_2)^2$
	3. 迭代阈值法：$T_0=\frac{L_{low}+L_{high}}{2}$，$T_i=\frac{\mu_1+\mu_2}{2}$
	4. 最大熵方法：$E_1=-\Sigma_{i=0}^{T}\frac{p_i}{P_1}\ln{(\frac{p_i}{P_1})}$，$E_2=-\Sigma_{T+1}^{L-1}\frac{p_i}{P_2}\ln{(\frac{p_i}{P_2})}$
（2）局部阈值分割方法，根据像素的灰度信息和像素周围局部区域性质来选取阈值

###### 27. 基于区域的图像分割：

· 区域生长法：
	· 简单生长法：点—点
	· 质心生长法：区域—点
	· 区域生长法：区域—区域
· 分裂合并：按方差阈值分裂，按均值阈值合并

###### 28. 图像退化模型：

· 空域退化模型：$g(x,y)=h(x,y)\otimes f(x,y)+n(x,y)$
· 频域退化模型：$G(u,v)=H(u,v)F(u,v)+N(u,v)$
· 特性：线性+平移不变性

###### 29. 维纳滤波，功率谱和信噪比：
$$功率谱：P(f)=\lvert F(f)\rvert^2,\ \ \ \ F\ 是对信号\ f\ 的傅里叶变换$$$$信噪比：SNR=\frac{P_{signal}}{P_{noise}}，信号功率除以噪声功率$$
· <font color="#00ffb0">维纳滤波最优化滤波器</font> $W$：$\hat{F}(u,v)=W(u,v)G(u,v)$
$$W=\frac{H^{*}}{\lvert H\rvert^2+\frac{E[\lvert N\rvert^2]}{E[\lvert F\rvert^2]}}$$
· 目的（原理）：降低 $\hat{f}$ 和 $f$ 的差的期望值

###### 30. 几何失真校正：

· 直接矫正法（向前映射法）：直角坐标系点映射到非坐标系点
· 间接矫正法（向后映射法）：非坐标系点映射到直角坐标系点
· 最邻近插值法：取四角最邻近的点
· 双线性插值法：2———2.6——3：3×0.6+2×0.4=2.6

