### 壹  计算复杂性理论概述

#### 
##### 
##### 

###### · 可计算与图灵机：
· **计算**：给定输入，经过有限步骤的操作过程，得到输出结果
· 不可计算问题：计算机进入无限循环
· 用符号：{ 0, 1 }* 表示任意由 0 和 1 构成的串
· **图灵机**：
	· 非正式而言，计算机算法 f 就是一套机器规则，给定任何输入 x ∈ { 0, 1 }* ，计算 f(x)
	· 基本操作：读取 — 暂存区（规则）— 写出
	· 运行时间（running time）是这些基本操作执行的次数

<font color="#ffc000">例</font>：布尔函数 <font color="#00b0f0">PAL</font> 定义如下：如果任意 x ∈ {0, 1}* ，如果 x 是<font color="#00b0f0">回文</font>，则 PAL(x)=1，否则值为 0，给出一个计算 PAL 的图灵机 M，它将用少于 <font color="#00b0f0">3n</font> 个步骤完成
~~~
· 证明：
图灵机 M 有 3 条带（即输入带、工作带和输出带）和字母表{ △, □, 0, 1 }，它如下进行操作：
1. 将输入复制到读写工作带上 -> n
2. 将输入带带头移动到输入的开始位置 -> n
3. 输入带带头向右移动，工作带带头向左移动；如果机器在带头移动中的任何时刻发现有两值不同，则停机并输出 0 -> n
4. 停机并输出 1
~~~

· 等价变形：
1. 字母表长度的等价变形：一个字母用多位二进制数表示：
![[复杂度理论图/复杂度理论图1-1.png]]
（图一：字母表长度的等价变形）
2. 纸带条数的等价变形：多个纸带的内容可以压缩到一个纸带上：
![[复杂度理论图/复杂度理论图1-2.png|500]]
                               （图二：纸带条数的等价变形）
3. 单、双向读取的等价变形：纸带弯折的单向读取可以实现双向读取的效果：
![[复杂度理论图/复杂度理论图1-3.png|600]]
                            （图三：单、双向读取的等价变形）

· 不可计算性简介：存在不能在任何有限次步数计算完成的函数
· **定理一**：存在不能被任意图灵机计算的函数 UC：{ 0, 1 }* —> { 0, 1 }
~~~
· 证明：
函数 UC 定义如下：对于任意 α∈{0,1}*，如果 Mα(α)=1, 则 UC=0；否则 UC(α)=1
	为导出矛盾，假设函数 UC 是可计算的，因此存在图灵机 M 使 M(α)=UC(α) 对任意的 α∈{0,1}∗ 成立（图灵机定义）；于是有 M(⌊M⌋（标准二进制表示）)=UC(⌊M⌋)，然而根据 UC 的定义有 UC(⌊M⌋)=1⟺M(⌊M⌋)≠1 -> 矛盾！
~~~

· 停机问题：函数 HALT 以序对 < α, x > 为输入，它输出 1 当且仅当 α 表示的图灵机 Mα 在输入 x 上会在有限步骤内停机
· **定理二**：函数 HALT 不能被任何图灵机计算
~~~
· 证明：
	为了导出矛盾，假设存在计算函数 HALT 的图灵机 M_HALT，用 M_HALT 构造一个计算函数 UC 的图灵机 M_UC，这与定理 1 矛盾
	图灵机 M_UC 的构造如下：对于输入 α，M_UC 运行 M_HALT(α,α)，如果结果是 0（即 M_α 在 α 上不停机），则 M_UC 输出 1，否则 M_UC 用通用图灵机计算 b=M_α(α)；如果 b=1 则 M_UC 输出 0，否则 M_UC 输出 1
	在 M_HALT(α,α) 会在有限步骤内输出 HALT(α,α) 的假设下，图灵机 M_UC 将输出 UC(α)
~~~
· 以上证明过程中的技术称为**归约**：定理的证明已经表明，如果假设存在计算 HALT 的算法，则必存在计算 UC 的算法；这就将对 UC 的计算归约到了对 HALT 的计算
· 通常，<font color="#00b0f0">归约技术用于证明问题 B 至少同问题 A 一样难</font>，这是通过证明“<font color="#00e0f0">如果给定求解问题 B 的算法，则存在求解问题 A 的算法</font>”来完成

###### · P 问题：
· **复杂度**类是一组可以在给定资源中计算的函数
· **布尔函数**：决策问题或语言
· 设 T：N →N 为某函数，设 **DTIME ( T ( n ) )** 是所有布尔（一位输出）函数的集合，这些函数在 c · T(n) 的时间内可计算，常数 c>0（ DTIME ( T ( n ) ) 可理解成 O ( T ( n ) ) ）$$P=U_{c>=1}DTIME(n^c)$$
· **P 问题**：包含可以使用确定型图灵机在多项式时间内解决的决定性问题，例如最大独立集问题

###### · NP 问题：
· <font color="#00b0f0">从头开始解决问题</font>和<font color="#00b0f0">验证给的的解决方案</font>之间有很大的区别
· P 问题是一类可以有效求解的决策问题
· **NP 问题**是能被有效验证其解的问题集
· P 问题是否等同于 NP 问题，现在仍未解决

· 如果给定一个输入 x，可以很容易地验证 x 是问题的真解（或者 x 在语言中）
· 如果给出 x 的多项式大小的解，就可以证明这是一个 NP 问题

· P 问题与 NP 问题的关系：P ⊆ NP ⊆ U<sub>c>1</sub>DTIME(2<sup>n<sup>c</sup></sup>)（在 2<sup>n<sup>c</sup></sup> 复杂度内可以解决的问题）
· **NP 问题**：包含可以使用非确定型图灵机在多项式时间内解决的决定性问题
· **非确定性图灵机（NDTM）**：包括两个过度函数 δ<sub>0</sub> 和 δ<sub>1</sub>，一个特殊状态 q<sub>accept</sub>
· 对于非确定性图灵机（NDTM M），M 在每个计算步骤中选择两个过度函数中的一个：
1. 输出 1：选择的序列会使图灵机 M 达到接受停机状态
2. 输出 0：每种选择的序列都会使 M 非接受状态停机

· 如果对于每个输入 x∈{0,1}* ，以及每个非确定性选择序列，M 达到停止状态或在 T(|x|) 步内运行结束，则代表图灵机 M 运行在 T(n) 时间内
· NP 问题的定义：设函数 T：N →N 且 L ⊆ {0,1}* ，如果存在常数 c>0 和 c · T(n) 时间的 NDTM M，使得对于任意的 x∈{0,1}* ，都有 x∈L ⟺ M(x)=1，则称 L ∈ NTIME ( T (n) ) 
· NP 问题的定理定义：$$NP=U_{c∈N}NTIME(n^c)$$

###### · 归约和 NP 完全性：
· 多项式时间 Karp 的语言 A⊆{0,1}* 可以归约为语言 B⊆{0,1}* ：如果存在一个多项式时间可计算函数 f：{0,1}* —> {0,1}* ，使得：∀x∈{0,1}* ，x∈A ⟺ f(x)∈B，表示为 A ≤<sub>p</sub> B
1. 如果对于任意 A∈NP，都有 A ≤<sub>p</sub> B，则 B 是 NP-hard 问题（NP 难问题）
2. 如果对于任意 A∈NP，都有 A ≤<sub>p</sub> B，且 B 是 NP 问题，则 B 是 NP-completeness（NP 完全问题）【既是 NP 难问题，又是 NP 问题的是 NP 完全问题】

· 多项式归约的性质：
1. *传递性*：如果 A ≤<sub>p</sub> B 且 B ≤<sub>p</sub> C，则 A ≤<sub>p</sub> C
2. *NP 难语言至少和其他 NP 语言一样难*：如果证明出了 A 是 NP-hard 问题且 A∈P，那么 P=NP
3. *如果任何 NP 难问题都可以在多项式时间内确定，则 P=NP*：A 是 NP 难问题，那么 A∈P⟺P=NP
![[复杂度理论图/复杂度理论图1-4.png]]
                      （图四：P、NP、NPC、NP-hard 问题的关系）

###### · 库克列文（Cook-Levin）定理：
· 布尔公式和 CNF 形式：一些最简单的 NP 完全问题的例子来自命题逻辑
· 一个关于变量 u1，u2，……，un 的布尔公式，由变量和逻辑操作符 AND(^)、NOT(¬) 和 OR ( _ ) 组成
· 对于布尔公式 φ，如果存在成真赋值，则称为可满足的，否则是不可满足的
· 如果 φ 是合取范式（conjunction normal form，简称 CNF ），其每一项都是析取式“从句”，这些析取式“从句”中变量（文字）最多的一项含有 k 个变量（文字），则 φ 称为 kCNF

· <font color="#00b0f0">可满足的 CNF 式</font>表示为 **SAT**，<font color="#00b0f0">可满足的 3CNF 式</font>表示为 **3SAT**
· **Cook-Levin 定理**：
	1. SAT 是 NP-complete 问题
	2. 3SAT 是 NP-complete 问题

· **合取范式的满足性问题**：
问题描述：给定一个合取范式 α，判定它是否可以满足
~~~
· 如果一个布尔表达式是一些因子和之积，则称之为合取范式，简称 CNF；这里的因子是变量 X 或 x
（例如 (x1+x2)(x2+x3)(¬x1+¬x2+x3) 就是一个合取范式，而 x1·x2+x3 就不是合取范式，而是析取范式）
· 要证明 CNF-SAT∈NPC，只要证明在 Cook 定理中定义的布尔表达式 A,……,G 或者已是合取范式，或者有的虽然不是合取范式，但可以用布尔代数中的变换方法将他们化成合取范式，而且合取范式的长度与原表达式的长度只差一个常数因子
~~~
· **证明 3SAT 是 NPC 问题**：
~~~
在图灵机 M 中，假定给定任何长度的输入，我们可以定义一个函数 inputpos(i) 和 prev(i)，inputpos(i) 表示输入带头在 i 位置，prev(i) 表示 M 在其工作中访问同一位置的 i 之前的最后一步
~~~
![[复杂度理论图/复杂度理论图1-5.png]]
（图五：inputpos(i) 和 prev(i) 函数工作原理）
~~~
用 Q 表示 M 的可能状态集合，用 Γ 表示 M 的字母表，M 在特定步数 i 上对某个输入 y 执行的快照是三元组 <a,b,q>∈Γ×Γ×Q；其中 a、b 是 M 的磁头从两个磁带中读取的符号，q 是 M 在第 i 步所处的状态
~~~
![[复杂度理论图/复杂度理论图1-6.png|450]]
                            （图六：三元组 < a, b, q > 工作原理）
~~~
对于每一个 m∈N 和 y∈{0,1}^m，m 在第 i 步对输入 y 执行的快照取决于：(1) 它在第 i-1 步的状态，(2) 它的输入磁带和工作磁带当前单元的内容，把这个关系写成：
~~~
$$z_{i}=F(z_{i-1},z_{prev(i)},y_{inputpos(i)})$$

· **将 SAT 归约成 3SAT**（ SAT <=<sub>p</sub> 3SAT ）：
~~~
· 证明：
    将一个 CNF 公式 φ 映射到一个 3CNF 公式 ψ，使得 ψ 是可满足的当且仅当 φ 是可满足的，首先证明 φ 是 4CNF 的情况：设 C 是 φ 的析取式“从句”，设 C=u1V¬u2V¬u3Vu4
    添加一个新变量 z，并将 C 替换为一对“从句”：C1=u1V¬u2Vz，C2=¬u3Vu4V¬z；显然，如果 C 成真，则 z 存在一个赋值使得 C1 和 C2 均成真；反之亦然，如果 C 为假，则无论 z 赋什么值，C1 与 C2 必有一假
    由此通过增添新变量将 kCNF 转化为一个 (k-1)CNF 和 3CNF，经过这样的反复变换可以将 SAT 归约成 3SAT
~~~

· 库克和列文给出了 NP 问题可以被归约为 SAT 这一定理
· 证明 L 是 NPC 的方法：将 SAT 或 3SAT 归约到 L
· 一旦知道 L 是 NPC，则可以通过把 L 归约到 L' 证明 NP 语言 L' 是 NPC

· Clique（最大团问题）是 NPC 问题：
· **Clique（最大团问题）**：给定无向图 G 和一个整数 K，确定是否存在一个至少包含 K 个顶点的子集 S，使得每两个不同的顶点 u，v∈S 之间都有一条边
· 方法：将 3SAT 归约到 Clique（析取式“从句” —> 图）

· 3SAT <=<sub>p</sub> CLIQUE 的证明（析取式“从句” —> 图）：
1. 顶点：每个析取式“从句”的成真赋值
2. 边：一致赋值之间的顶点连线
![[复杂度理论图/复杂度理论图1-7.png|400]]
                             （图七：由析取式从句向图的转换）
· 多少条连线就是多少个析取式“从句”：
![[复杂度理论图/复杂度理论图1-8.png|400]]
                              （图八：最多兼容顶点构成最大团）

· 证明最大独立集（Indep-Set）问题、顶点覆盖（Vertex-Cover）问题是 NPC 的方法：将 Clique 归约为它们：
	· Clique ≤<sub>p</sub> Indep-Set：图 G 有 m 大小的团，则其补图 G' 有 m 大小的独立集
	· Indep-Set ≤<sub>p</sub> Vertex-Cover：图 G 有 m 大小的独立集，则有（n-m）大小的能覆盖全局的顶点集

· 用<font color="#ffc000">判定问题</font>（“给定的公式是否是可以满足的”）而不是<font color="#ffc000">搜索问题</font>（“如果给定的公式是可满足的，找出一个满足性赋值”）来定义 NP 这一概念，显然搜索问题比判定问题更难，因此如果 P ≠ NP，则 NP 与 NPC 均不能在多项式时间求解
· 对于 NPC 问题而言，如果它的判定形式可以在多项式时间求解（即 P=NP ），则相应的搜索问题也可以在多项式时间内求解，从这个意义上说，NPC 的判定形式和搜索形式是等价的

###### · coNP 问题：
· **coNP**：假如 L⊆{0,1}* ，定义 L' 为 L 的补集，即 L'={0,1}* -L，定义：coNP = { L : L' ∈ P }
· 例：L 是所有素数组成的语言，所以 L 中的数字都不能因数分解，找到可以因数分解的数字是在验证这个问题的否定情况，如果验证否定情况可以在多项式时间完成，则 L 是 coNP 问题；现已知因数分解可以在多项式时间完成，所以 L 是 coNP
· 注意：coNP 不是 NP 的一个补充，它们有一个非空交集，P 中的每一个语言都在 coNP ∩NP 中
· **coNP-complete**：如果这个语言在 coNP 中并且每个 coNP 语言都可以在多项式时间 Karp 归约到它，则这个语言是 coNP 完全的

###### · EXP 和 NEXP：
· 一个问题属于 **EXP** 类，如果它可以在指数时间内（即时间复杂度为 2<sup>poly(n)</sup>，其中 n 是输入规模）解决
· 一个问题属于 **NEXP** 类，如果它可以在非确定性指数时间内（即时间复杂度为 2<sup>poly(n)</sup> ）解决
$$EXP=U_{c\ge0}DTIME(2^{n^c})$$$$NEXP=U_{c\ge0}NTIME(2^{n^c})$$
· 因为 NP 中的所有问题都可以通过暴力搜索解决，故：
$$P⊆NP⊆EXP⊆NEXP$$


### 贰  近似算法概要

#### 
#####
#####

###### · 近似算法提出和近似比：
· 研究如何做出决策以达到一些最佳可能的目标，衍生出离散优化学
· 最有趣的离散优化问题是 Np-hard：除非P=NP，否则没有有效的算法可以找到最优解
· **近似算法**：优化问题的 **α 近似算法**是一种多项式时间算法，对于问题的所有实例产生的解的值在最优解值的 α 因子范围内，α 称为**近似比**：
	1. α>1 => 对于最小化问题，如最小定点覆盖问题
	2. α<1 => 对于最大化问题，如最大团问题
· 例：最大化问题的$\frac{1}{2}$近似算法是指一个多项式时间算法，它总是返回至少是最优值的一半的解

· **多项式近似方案**：一个多项式时间近似方案（**PTAS**）是一个算法族 {${A_{ϵ}}$} ，其中任取 ϵ>0，都使得 A<sub>ϵ</sub> 是一个 *(1+ϵ)-近似问题（对于最小化问题）* 或 *(1-ϵ)-近似问题（对于最大化问题）*
例：背包问题、欧几里得旅行商问题

· 存在着一类不那么容易解决的问题，称作 *MAX SNP*
例：最大可满足性问题（MAX-SAT）、最大切割问题
![[复杂度理论图/复杂度理论图1-9.png]]
（图九：最大切割问题图示）
· `定理`：对于任何 MAX SNP-hard 问题，*除非 P=NP*，否则不存在多项式时间逼近算法方案

· 有些问题很难，如求解最大团问题
· `定理`：设 n 表示任意输入图中的顶点数，并考虑任意常数 ϵ>0，不存在一个 O(n<sup>ϵ-1</sup>) 的近似算法解决最大团问题，*除非 P=NP* 【这意味着，最大团有可能是 n，但算法给出的近似解却是 1 】

###### · Set cover 与线性规划：
· **集合覆盖问题（Set cover problem，SCP）**：给定一组元素 E={ ${e_1,…,e_n}$ } ，S1, S2,……，Sm 是 E 的子集，其中每一个子集都有自己的权重 wi，权重均大于零；目标是找到一个最小权重的子集集合，覆盖整个 E；如果每个集合的权重都是 1，则这样的问题称为无权集合覆盖问题
· 证明有权集合覆盖问题是 NP-complete：
~~~
· Weighted set cover 的判定问题：存在 weight 之和为 k 的集合 C（ C是{S1, S2,…,Sm} 的子集）使得 C 能够覆盖 E
· Weighted set cover 是 NP 问题：给出 C 在 P 时间内很容易验证 C 的 weight 之和是不是 k 且 C 能不能覆盖E
· 任何 NPC 问题 ≤p Weighted set cover
· 无权 SCP 是 SCP 的一个特例，任何 NPC 问题 ≤p unweighted set cover ≤p Weighted set cover
· 为了证明顶点覆盖（vertex cover）问题是 NPC，只需证明 vertex cover ≤p unweighted set cover

· 证明：
① P 时间内用图构造集合：
	· 令图里的每一条边为 e1,…,en，所有的边构成 set cover 的全集 E={e1,…,en}
	· 图里的每个顶点 vi 是 E 的子集，vi=⋃{ej}（并集） 即这些 “ej” 共享同一个顶点 vi
② 证明 vertex cover 判定为真当且仅当对应的 set cover 为真
	· 如果 C 是 set cover 的解，我们证明 C 是构造的图上的一个顶点覆盖
	· 根据图的构造规则，C 中的每个子集 Sj 都对应图的一个顶点
	· 根据set cover的定义，⋃{Sj}=E，根据图的构造规则，E就是图上所有的边：也就是每给出一个 set cover 的解，都能对应一个 vertex cover 的解
	· 同理，如果 V 是图的一个顶点覆盖，则 V 的每个顶点都是满足 set cover 条件的一个子集 Sj，由于 V 能覆盖所有的边，则 ⋃{Sj}=E 必然成立
~~~

· **线性规划（Linear programming）**：
1. 每一个线性规划或整数规划都是用一定数量的决策变量来表述的，这些决策变量代表需要做出的某种决策
2. 变量受到一系列线性不等式和等式的约束
3. 对变量的任何实数赋值，使所有的约束条件都得到满足，就称为*可行解（ feasible solution ）*

· Set cover problem 中的约束性（constraint）：
	· 决策目标：决策需要选择拿下子集 Sj
	· 创建一个决策变量 xj 来表示选择
		· 当 Sj 被选择，xj 赋值为 1，否则赋值为 0
		· xj 取值范围的约束性为 0 ≤ xj ≤ 1，但这个条件无法保证 xj ∈ { 0, 1 }
	· 可以将问题表述为整数程序，以排除分数解
	· 还应确保任何可行解可以使集合中的每一个元素 ei 都被覆盖，即包含 ei 的子集 Sj 至少有一个被选中

· 线性和整数规划是由决策变量的线性函数定义的，称为目标函数
· 寻求一个可行的解决方案，对于这个目标函数，要么求最大值，要么求最小值，这样的解称为*最优解*
· 解线性规划其实就是寻找最优解的过程
· 考虑 Set cover problem 问题，目标就是找到 minimum weight，也就是 minimize $∑^m_{j=1}w_jx_j$
· 将 Set cover 写成 **整数规划（interger programming）** 的形式：
1. 最小化：$∑^m_{j=1}w_jx_j$
2. 限制：
	1. $∑_{j:e_{i}∈S_j}x_j>=1,(j=1,……,n)$ 
	2. $x_j∈$ { 0, 1 }，（j = 1, ……, n）
· **令 $OPT$ 表示 set cover 问题的最优解，$Z_{IP}^*$ 表示整数规划的最优解，则有 $Z_{IP}^*=OPT$**
（一般来说，整数程序不能在多项式时间内求解，显然，因为上述过程 set cover ≤<sub>p</sub> integer program）

· 然而，**线性规划**是多项式时间可解的；二者的区别仅在于，线性规划不要求 xj 必须是整数：
1. 最小化：$∑^m_{j=1}w_jx_j$
2. 限制：
	1. $∑_{j:e_{i}∈S_j}x_j>=1,(j=1,……,n)$ 
	2. $x_j>=0,(j=1,……,m)$
（xj 小于等于 1 的限制是不必要的：在任何问题的最优解中，xj>1 都可以归约到 xj=1，且不增加成本，不影响解决方案的可行性）
· **线性规划是整数规划的松弛形式**：
· 每个整数规划的可行解也是线性规划的解，即如果一个解满足整数规划，那么它必也满足线性规划的所有条件
· 每个整数规划的可行解对应值，相应地在线性规划上的值也是相同的，因为二者的目标函数相同
· $Z_{LP}^*$ 表示线性规划的最优解，则整数规划的任何最优解对于线性规划都是可行的，并且有解 $Z_{IP}^*$
· 因此 $Z_{LP}^*<=Z_{IP}^*=OPT$ ，也就是说线性规划给出的最小值是整数规划不可能达到的：
	整数规划给出的每一个最小值，都包含在线性规划里
· 因此，线性规划在 P 时间内给出了整数规划（最小化目标函数）的一个下界（lower bound）
【最大化目标函数则是上界（upper bound）】
· 后面将用 **LP** 代表线性规划，用 **IP** 表示整数规划

###### · 确定性 rounding 算法：
· 假定我们解决了集合覆盖问题的线性规划松弛问题，令 x* 表示 LP 的最优解，那么我们如何恢复集合覆盖问题的解决方案呢？
· 给定 LP 解 x* ，包含子集 Sj 当且仅当 $x_j^*>=\frac{1}{f}$ ，其中 𝑓 是任何元素出现的最大集合数
· 形式上，设 I 表示解 x* 中子集的指标 j，将分数解 x* 整数化 x ̂：当 $x_j^*>=\frac{1}{f}$ 时 x ̂=1，否则 x ̂=0
· 例：E={a,b,c,d,e}，S1={b,c}，S2={a,b,d}，S3={a,e}，S4={c,e}，S5={c,d}，S6={d,e}，则 *f=3*
~~~
设 LP 给出 x1=0.3，x2=0.7，x3=0.3，x4=0.5，x5=0.3，x6=0.3；此时 a 的系数 0.7=0.3=1，b=1，c=1.1，d=1.3，e=1.1；则 rounding 之后，x1=x3=x5=x6=0；x2=x4=1
~~~
接下来要证明 x ̂是 IP 的一个可行解，且 I 实际上是索引的一个集合
· `引理`：子集 Sj (j∈I) 的集合是一个覆盖集
~~~
· 证明：
证明引理就是证明每一个元素 ei∈E 都被 Sj(j∈I) 所包含
∵ x* 是线性规划的解
∴ 线性规划的“限制1”（∑(Xj*)>=1）必成立
根据 fi 的定义，每个 ei 被包含的次数，是 fi 个 Xj* 加和
因为“限制1”，所以至少有一个 (Xj*)>=(1/fi)
由于 f 是 fi 中的最大值，所以至少有一个 (Xj*)>=(1/f)
· 根据 rounding 的规则：如果 (Xj*)>=(1/f) 则设置 (^X)j=1
∴ 至少有一个 (Xj*) 会使得 (^X)j=1，所以 ei 必被 (^X) 覆盖
~~~

· 还可以证明这个舍入过程 Rounding 产生了一个近似算法：
	· 舍入算法是覆盖集问题的 f - 近似算法
~~~
· 证明：
很显然这个算法可以在 P 时间运行完成
根据构造：(xj*)>=1/f, 即对于每一个 j∈I，都有 1<=f·(xj*)
于是：∑(j∈I)wj <= ∑(j=1 to m)wj·(f·(xj*)) = f·∑(j=1 to m)wj·(xj*) = f·[Z*_(LP)]
<= f·OTP
~~~

###### · Primal-Dual（原始对偶）问题：
· 通常考虑给定问题的线性规划松弛的对偶是有用的
· 用覆盖集问题简要介绍原始对偶：
1. 首先，我们假设每个元素 $e_i$ 对其覆盖的集合收取非负价格 $y_i\geq 0$
2. 对低权重子集收取低价格，高权重子集收取高价格
3. 对于每个子集 $S_j$，我们对价格有以下限制：$\Sigma_{(i:e_i\in S_j)}y_i\leq w_i$
· 通过下面的线性规划，可以找到这些元素的最高总价：
1. **对偶线性规划**：
$$最大：\Sigma_{i=1}^ny_i$$$$限制：\Sigma_{(i:e_i\in S_j)}\ y_i\leq w_j,\ \ \ \ j=1,\ldots,m$$$$y_i\geq 0,\ \ \ \ i=1,\ldots,n$$
2. **原始线性规划**：
$$最小：\Sigma_{i=1}^nw_jx_j$$$$限制：\Sigma_{(i:e_i\in S_j)}\ x_j\geq 1,\ \ \ \ i=1,\ldots,n$$$$x_j\geq 0,\ \ \ \ j=1,\ldots,m$$

· Dual（对偶）对 primal（原始）的每个限制都设置了变元，对 primal 的每个变元都设置了限制
![[复杂度理论图/复杂度理论图1-10.png|550]]
                       （图十：原始线性规划与对偶线性规划的比较）

· 对偶线性规划有许多非常有趣和有用的性质：
· 例：设 𝒙 为覆盖线性规划松弛集的任意可行解，设 𝒚 为价格的任意可行集，然后考虑对偶解的值：$$\Sigma_{i=1}^ny_i\leq \Sigma_{i=1}^ny_i\cdot\Sigma_{(j:e_j\in S_j)}w_j$$
因为线性规划的条件：$$\Sigma_{(j:e_j\in S_j)}x_j\geq 1$$
· 把上式右侧等价整理，有：$$\Sigma_{i=1}^ny_i\cdot\Sigma_{(j:e_j\in S_j)}w_j = \Sigma_{i=1}^mx_i\cdot\Sigma_{(j:e_j\in S_j)}y_j$$根据对偶线性规划的条件：$$\Sigma_{(j:e_j\in S_j)}y_i\leq w_i$$有：$$\Sigma_{i=1}^mx_i\cdot\Sigma_{(j:e_j\in S_j)}y_j \leq \Sigma_{i=1}^mx_jw_j$$
· 所以，对于 Dual 的目标函数：$$\Sigma_{i=1}^ny_i$$和 Primal 的目标函数：$$\Sigma_{i=1}^mw_ix_i$$有：$$\Sigma_{i=1}^ny_i\leq\Sigma_{i=1}^mw_ix_i$$
· 综上得出：$$\Sigma_{i=1}^ny_i\leq Z_{LP}^*\leq OPT$$这称为线性规划的**弱对偶性质**

· *强对偶*：只要原线性规划和对偶线性规划都存在可行解，它们的最优值是相等的，即：如果 $x^*$ 是集合覆盖线性规划松弛的最优解，$y^*$ 是对偶线性规划的最优解，则 $\Sigma_{i=1}^mw_ix_i^*=\Sigma_{i=1}^ny_i^*$

· <font color="#ffff00">偶线性规划解的原理有时可以用来推导好的近似算法</font>：
	· 设 y* 是 Dual LP 的最优解，假设 y* 满足的约束条件是 $\Sigma_{(i:e_i\in S_j)}y_i=w_j$，设 I' 是表示该解中子集的指标，则需要证明该算法也是覆盖集问题的 f - 近似算法
· 子集 Sj，j∈I' 的集合是一个覆盖集：
~~~
· 反证法：
假设存在一些未覆盖的元素 𝑒𝑘，然后对于每个包含 𝑒𝑘 的子集 𝑆𝑗，一定有：∑(i:ei∈Sj) yi* < wi
~~~
令：$$\epsilon=min_{(j:e_k\in S_j)}(w_j-\Sigma_{(i:e_i\in S_j)}y_i^*)$$
~~~
显然，ε>0
现在考虑一个新的对偶解 y' 满足 (yk')=(yk*)+ε，并且 y' 的每个其他组成部分与 y* 中的相同
那么对于每一个满足 ek∈Sj 的 j，y' 是一个对偶可行解
~~~
$$\Sigma_{(i:e_i\in S_j)}y_i^{'}=\Sigma_{(i:e_i\in S_j)}y_i^{*}+\epsilon=w_j$$
~~~
由 ε 的定义，对于 j（ek 不属于 Sj）有：
~~~
$$\Sigma_{(i:e_i\in S_j)}y_i^{'}=\Sigma_{(i:e_i\in S_j)}y_i^{*}\leq w_j$$
此外：$$\Sigma_{i=1}^ny_i^{'}\textgreater \Sigma_{i=1}^ny_i^*\ \ 与最优解\ y^*\ 相矛盾$$

· <font color="#ffff00">上述对偶舍入算法是覆盖集问题的 f - 近似算法</font>：
~~~
· 证明：
中心思想是以下“收费”观点:
当我们选择一个集合 𝑆𝑗 作为覆盖时，我们通过向它的每个元素 𝑒i 收取 𝑦i∗ 的“钱”来“支付”
对于每个包含元素的集合，每个元素最多被“收费”一次（因此总共最多“收费” f 次）
~~~
因此，总成本至多为：$$\Sigma_{i=1}^my_i^*$$或 𝑓 乘以对偶目标函数
~~~
· 更严格来说，因为 j∈I‘ 当且仅当 wj=∑(i:ei∈Sj) yi∗，这个集合覆盖 I' 的价格是：
~~~
$$\Sigma_{(j\in I')}w_j=\Sigma_{(j\in I')}\Sigma_{(i:e_i\in S_j)}y^*_i=\Sigma_{i=1}^n|\{ j\in I':e_i \in S_j \}|\cdot y^*_i$$
$$\leq\Sigma^n_{i=1}f_iy_i^*\leq f\cdot\Sigma_{i=1}^ny^*_i\leq f\cdot OPT$$
其中：$$\Sigma_{i=1}^n|\{ j\in I':e_j\in S_j \}|\cdot y^*_i$$
~~~
当交换求和的顺序时，(𝑦i*) 的系数等于这一项出现的总次数
~~~

· 如果 I 指向原始四舍五入算法的解，则 𝐼 包含于 𝐼'，这遵循最优线性规划解的一个性质，称为**互补松弛性**
· 对于集合覆盖线性规划松弛的任何可行解，以及对偶线性规划的任何可行解，有：$$\Sigma_{i=1}^ny_i\leq\Sigma_{i=1}^ny_i\cdot\Sigma_{(j:e_i\in S_j)}x_j=\Sigma_{j=1}^mx_j\cdot\Sigma_{(i:e_i\in S_j)}y_i\leq\Sigma_{j=1}^mx_jw_j$$
· 根据强对偶性，最优解为 x* 和 y*，有：$$\Sigma_{i=1}^ny_i^*=\Sigma_{j=1}^mw_jx_j^*$$所以上面的两个不等式此时可以取等号，意味着：
1. 只要当 $y_i^*\textgreater0$，则 $\Sigma_{(j:e_i\in S_j)}x^*_j=1$
2. 只要当 $x_j^*\textgreater0$，则 $\Sigma_{(i:e_i\in S_j)}y^*_i=1=w_j$
· 即：只要当线性规划变量（原始或对偶）非零时，对应的对偶或原始约束始终是严格的

· 因此，如果溢（x*）和（y*）是最优解，则互补松弛性条件必须成立
· 反之也成立：如果（x*）和（y*）分别是可行的原解和对偶解，则如果互补松弛条件成立，则两个目标函数的值相等，因此解一定是最优的
· 若对于任何原始最优解 $x^*\textgreater 0$，则 $S_j$ 对应的对偶不等式对于任何对偶最优解 $y^*$ 必须是严格的
· 回头考虑令 $j\in I,\ x^*_j\textgreater1/f$，因此每一个属于 I 的 j 都属于 I'，即 $I\subset I'$

· 构造对偶解：原始-对偶方法（ primal -dual method ）：
	· 上述 primal 和 dual 方法的缺点：需要解线性规划
![[复杂度理论图/复杂度理论图1-11.png]]
（图十一：构造对偶解）

例：$$E=\{a,b,c,d,e\},\ \ S_1=\{b,c\},\ \ S_2=\{a,b,d\},\ \ S_3=\{a,e\},$$$$S_4=\{c,e\},\ \ S_5=\{c,d\},\ \ S_6=\{d,e\},\ \ f=3$$
设：$$w_1=2,\ \ w_2=3,\ \ w_3=w_4=w_5=w_6=2$$则：$$f_a=2,\ \ f_b=2,\ \ f_c=f_d=f_e=3,\ \ f=3$$
1. a 没被 cover，设将 S2 放入 Sj，y=3，已被 cover 的有 a、b、d
2. c 没被 cover，设选 S5，y=5，已被 cover 的有 a、b、c、d
3. e 没被 cover，设选 S6，此时 y=7，得到 set cover 的解

· 上述算法是覆盖集问题的 𝑓 - 近似算法，这种算法称为原始对偶算法
· 原始-对偶算法从一个对偶可行解开始，利用对偶信息推断出一个原始解

###### · Greedy（贪心）算法介绍：
· 贪心算法的工作原理是做出一系列的决定：每个决策都是为了优化特定的决策，即使这个局部最优（或“贪心”）决策序列可能不会导致全局最优解决方案
· Greedy 的优点：好理解、好实现，常用来作为启发式算法

· **Set cover 问题的 Greedy 算法**：
![[复杂度理论图/复杂度理论图1-12.png]]
（图十二：Set cover 问题的 Greedy 算法）
![[复杂度理论图/复杂度理论图1-13.png|550]]
                 （图十三：Set cover 问题的 Greedy 算法具体实现示例）

· **用 Greedy 求解 Set cover 的近似比**：
· 贪心算法是一种求解集合覆盖问题的 𝐻𝑛 - 近似算法
· 用 $H_k$ 表示 k 项的调和数：$H_k=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{k}$，于是有 $H_k\approx lnk$
· 定理：给定正数 $a_1,a_2,\ldots,a_k$ 和 $b_1,b_2,\ldots,b_k$，则有：$$min_{(i=1,\ldots,k)}\frac{a_i}{b_i}\leq \frac{\Sigma_{i=1}^ka_i}{\Sigma_{i=1}^kb_i}\leq max_{(i=1,\ldots,k)}\frac{a_i}{b_i}$$

· 证明贪心算法近似比：
~~~
· 证明：
	设 OPT 表示覆盖集问题的最优解的值，即最优解覆盖所有的 𝑛 个元素，解的总权重为 OPT，因此必须存在一个子集，它的元素的平均权重不超过 OPT/n
	类似地，在覆盖 𝑘 个元素之后，最优解可以用权值最多为 OPT 的解（假设前面覆盖 k 个元素的权值趋近于零）覆盖剩余的 𝑛−𝑘 元素，这意味着有一些子集覆盖了剩余的未覆盖元素，其平均重量最多为 OPT/(n-k)
	所以一般来说，贪心算法“支付”平摊不大于 OPT/(𝑛−𝑘+1) 的权值来覆盖第 k 个未覆盖的元素，总表达式为：
~~~
$$\Sigma_{k=1}^n\frac{1}{n-k+1}=H_n$$
~~~
现在将这个理论形式化：
	令 𝑛k 表示在第 k 个元素迭代开始时仍然未覆盖的元素的数量，如果算法需要 l 次迭代，那么 n1=n，n[l+1]=0
	任意选择一次迭代 𝑘，设 Ik 表示迭代从 1 到 𝑘−1 所选集合的下标，令 (Sj^) 在迭代开始时表示 Sj 中未覆盖元素的集合（j=1,……,m），即：(Sj^) = Sj - ⋃_(p∈I_k) Sp，则对于第 k 次迭代中的集合 j，有：
~~~
$$w_j\leq \frac{n_k-n_{k+1}}{n_k}\ OPT$$
（第 k 次迭代 cover 了多少 average weight）

· 设 I 包含最终解中集合的指标，则：$$\Sigma_{(j\in I)}w_j\leq\Sigma_{(k=1)}^l\frac{n_k-n_{k+1}}{n_k}OPT$$$$\leq OPT\cdot\Sigma_{(k=1)}^l(\frac{1}{n_k}+\frac{1}{n_k-1}+\frac{1}{n_{n+k}+1})$$$$OPT\cdot\Sigma_{i=1}^n\frac{1}{i}=H_n\cdot OPT$$

· 为了证明 $w_j\leq \frac{n_k-n_{k+1}}{n_k}\ OPT$，需要在第 k 次迭代中论证：
![[复杂度理论图/复杂度理论图1-14.png]]
                           （图十四：第 k 次迭代的权重不等式）
· 如果令 O 包含最优解集合的指标，那么上述式子遵循 $min_{(i=1,\ldots,k)}\frac{a_i}{b_i}\leq \frac{\Sigma_{i=1}^ka_i}{\Sigma_{i=1}^kb_i}\leq max_{(i=1,\ldots,k)}\frac{a_i}{b_i}$
· 由于 O 是一个集合覆盖，所以集合 ∑_(𝑗∈𝑂)(𝑠𝑗^) 必须包含所有剩余的 𝑛𝑘 未覆盖的元素
![[复杂度理论图/复杂度理论图1-15.png|450]]
                            （图十五：局部最优为整体最优解）

· 让 j 索引一个最小化比率的子集，因此有：
![[复杂度理论图/复杂度理论图1-16.png]]
                               （图十六：最小化子集不等式）
如果把子集 Sj 加到解中，那么将会有更少的未覆盖元素 | (Sj^) |，使得：n<sub>k+1</sub> = n<sub>k</sub> - | (Sj^) |，因此导出：
$$w_j\leq \frac{n_k-n_{k+1}}{n_k}\ OPT$$

· 用贪心算法求解 Set cover 的近似比的不严谨描述就是：
1. 求 Greedy 算法的近似比，其实就是 Greedy 运气最不好的时候给出的解
2. 每次 Greedy 选的是：
![[复杂度理论图/复杂度理论图1-17.png|84]]
                            （图十七：每次 Greedy 选取的子集）
比较“衰”的情况就是刚好错过了 OPT 要选的那个 $S_{j*}$，也就是对于 $S_{j*}$ 来说：
![[复杂度理论图/复杂度理论图1-18.png|196]]
                              （图十八：Greedy 的最坏情况）
3. 让情况“衰”到极致：假设 OPT 恰好只有一个集合，也就是  $w_{j*}$ = OPT，$S_{j*}$ = E，而 Greedy 每次选的 $w_j$ 只新覆盖一个元素，则：
$$\Sigma_{(j\in I)}w_j\leq \frac{OPT}{n}+\frac{OPT}{n-1}+ \cdots +\frac{OPT}{1}=H_n\cdot OPT$$

![[复杂度理论图/复杂度理论图1-19.png|500]]
                           （图十九：Greedy 最坏情况举例）

###### · 随机 rounding 算法介绍：
· 之前用线性规划松弛解 set cover 问题，再将分数解四舍五入为正数解，然而，该算法使用的是一种称为随机四舍五入的技术，而非确定性地舍入
· 设 x* 为 LP 松弛的最优解，期望的是将分数解的值取整为 0 或 1，这样就可以在不增加太多代价的情况下，得到 set cover 问题整数规划公式的一个解

· 随机舍入的中心思想是，将分数值 x* 解释为它被设置为 1 的概率（以 x* 的概率被置 1 ）
· 设 Xj 为随机变量，如果解决方案中包含子集 Sj，则该变量为 1，否则为 0，那么解的期望值是：$$E[\Sigma_{j=1}^mw_jX_j]=\Sigma_{j=1}^mw_jPr[X_j=1]=\Sigma_{j=1}^mw_jx^*_{j}=Z^*_{LP}$$或者仅仅是线性规划松弛的值，它不超过 OPT

· 然而，解决方案很可能不是一个固定的覆盖集
· 现在计算一个给定元素 ei 没有被上述过程覆盖的概率：
~~~
解：
这是解决方案中不包含任何包含 ei 的子集的概率，即：
~~~
![[复杂度理论图/复杂度理论图1-20.png|176]]
                            （图二十：不包含任何子集的概率）
~~~
由于 1-x ≤ e^(-x)，故可以写成：
~~~
![[复杂度理论图/复杂度理论图1-21.png]]
（图二十一：缩放后的不包含任何子集的概率）
· 从 LP 约束中得出的最终不等式：
![[复杂度理论图/复杂度理论图1-22.png]]
                       （图二十二：从 LP 约束中得出的最终不等式）

· 说明：虽然 $e^{-1}$ 是给定元素未覆盖概率的上界，但有可能任意接近这个边界，因此在最坏的情况下，这个随机四舍五入过程很可能不会产生集合覆盖
· 假设对于任意常数 c，可以设计一个多项式时间算法，其失败的机会最多为 $𝑛^{−𝑐}$，满足这个条件便认定是一个高概率的算法
· 如果能设计一个随机程序使得 ei 不被覆盖到的概率小于等于 $n^{-c}$，其中 c=2；“存在未被覆盖元素的概率” ≤ “每一个元素各自不被覆盖的概率之和” ≤ $\frac{1}{n^{c-1}}$，也就是说大概率集合会全覆盖

· 实际上，可以通过下面的方法来实现这样一个边界：对于每个子集 Sj，我们想象一枚硬币出现正面的概率为 （xj*），抛掷硬币 $c\ ln(n)$ 次，如果在任次试验中硬币出现正面，则把集合 Sj 纳入解中，否则不纳入
· 因此得到，Sj 不被包含的概率为：$(1-x^*_j)^{c\ ln(n)}$
· 则元素 ei 不被包含的概率：
![[复杂度理论图/复杂度理论图1-23.png|450]]
                    （图二十三：再次近似后的元素 ei 不被包含的概率）

· 结论：<font color="#ffff00">该算法是一个随机的 O ( ln(n) ) 的近似算法，产生一个高概率的集合覆盖</font>
· 当 $n \textgreater 2,\ c\textgreater 2$ 时，有：
![[复杂度理论图/复杂度理论图1-24.png|500]]
             （图二十四：随机 rounding 算法是一个随机的 O ( ln(n) ) 的近似算法）

