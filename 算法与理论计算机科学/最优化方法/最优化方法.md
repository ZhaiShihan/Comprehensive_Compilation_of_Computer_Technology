### 壹  智能技术的发展史与趋势

#### 述：
#####
#####

###### · 人工智能缘起：1956 年达特茅斯会议
· 旨在创立一门新学科
· “人工智能夏季研讨会”（ Summer Research Project on Artificial Intelligence ）
· 人工智能的两派观点：理解 v.s. 模仿
	· 逻辑和符号系统（逻辑派 / 符号派）—— 数学、几何等定理的自动证明
	· 模拟大脑的神经系统（神经网络派）
· 发布程序“逻辑理论家”：第一个可工作的 AI 程序（纽厄尔、司马赫）
![[最优化方法图/最优化方法图1-1.png|450]]
                                  （图一：达特茅斯大学）
· **麦卡锡**：会议召集人，时任达特茅斯学院数学系助理教授，LISP 语言和分时系统的发明人，1971 年图灵奖获得者
· **明斯基**：博士论文神经网，1969 年图灵奖获得者（第一个属于人工智能领域研究者的图灵奖），图灵奖获得者布鲁姆的导师，诺贝尔经济学奖得主纳什的同门师弟
· **塞弗里奇**：人工智能先驱，模式识别奠基人，控制论提出者维纳的学生
· **香农**：信息论创始人，计算机下棋理论基础奠定者
· **纽厄尔**：当时就职于兰德公司，与司马赫共同获得 1975 年图灵奖
· **司马赫**：时任 CMU 工业工程系主任，与纽厄尔共享 1975 年图灵奖，纽厄尔的老师，3 年后获得诺贝尔经济学奖，首批中科院外籍院士
· “当时直觉认识到实验心理学、理论语言学、认知过程的计算机模型，都是一个‘大家伙’里面的组成部分” —— 达特茅斯会议

###### · 神经网络初创：
· 神经网络开山之作：“A Logical Calculus of the immanent in Nervous Activity”，麦洛克和皮茨，1943 年（控制论的思想源泉之一）
· 第二个大突破：“感知机”（Perceptron）神经网络模型，罗森布拉特，1957 年
	· 可以完成简单的视觉处理任务
	· 证明了单层神经网络在处理线性可分的模式识别问题时可以收敛
·  感知机的失败：神经网络进入低潮
	· 不能解决 XOR 问题（异或问题）《感知机：计算几何学》明斯基
	· 2004 年 IEEE 设立罗森布拉特奖

###### · 神经网络复兴：
· 复兴背景：
	· 证明在神经网络多加一层并利用后向传播学习方法，可以解决 XOR 问题，沃波斯（递归神经网络 RNN 的原创者），1974 年
	· 视网膜和视觉皮层中神经细胞的处理模式，诺贝尔医学奖，1981 年
· 新型神经网络：霍普菲尔德网络，1982 年
	· 解决一大类模式识别问题
	· 各处一类组合优化问题的近似解
· 连接（Connection）主义运动
	· 两位心理学家和一位计算机科学家（辛顿）（深度学习先驱）
	· 文集 Parallel Distributed Processing（PDP）

###### · 深度学习兴起：
· 1980 年代起互联网的光芒掩盖了神经网：
	· 神经网络第二次衰落
	· 孕育深度学习的崛起，数据、算力
· 2006 年辛顿的两篇论文开辟这一新领域：
【深度学习：用很多层神经元构成的神经网络实现机器学习的功能】
	· 一层网络：一层函数
	· 多层网络：函数的嵌套
	· 网络越深表达能力越强，训练难度也急剧加大
	· 提出*降维*和*逐层预训练*的方法，使深度学习实用化成为可能
· **人工智能的范式**：<font color="#c000c0">大数据</font> + <font color="#ffc000">算力</font> + <font color="#92d050">深度学习</font>
（另一条路：*小数据* + *大任务* ）

###### · 深度学习实用化：
· 惊艳亮相：
	· SuperVision 绝对优势，国际大赛 ILSVRC，辛顿团队，2012 年
	· 1000 万张图像训练，15 万张图像测试，错误率 15% 以下
· 2009 年微软与辛顿合作，语音识别与同声传译系统
	· Skype、腾讯、科大讯飞等等
· 2013 年辛顿创业
	· 谷歌、微软、百度竞相收购，最终辛顿被谷歌招入旗下
· 2018 年辛顿凭借深度学习获得图灵奖（与杨立昆同年）
	· 见证人工智能几十年的起落与纷争，初衷不改

###### · 计算机下棋简史：
· 下棋：人工智能的标志之一
	· 图灵：1947 年编写了第一个下棋程序
	· 冯 · 诺依曼：1944 年提出两人博弈的 Minimax 算法
	· 香农：1950 年发表《计算机下棋程序》“Programming a Computer for Playing Chess”
· 跳棋插曲：
	· 1980 年代起最强的跳棋程序 Chinook，舍佛（阿尔伯塔大学）
	· 1950 年代起人类跳棋冠军丁斯利
	· 2007 年舍佛证明：对于跳棋，只要对弈双方不犯错，最终结果都是**和棋**
· 深蓝：
	· 第一个可以走完全局的下棋程序，IBM，1958 年：走一步需要 8 分钟
	· 司马赫的两次预言：
		1. 1957 年预言：10 年内下棋程序可以击败人类（未实现）
		2. 1965 年预言：20 年内下棋程序可以击败人类（未实现）
	· 列维与麦卡锡的打赌：
		· 1968 年打赌，10 年内机器能战胜列维（未实现）
		· 1978 年计算机下棋冠军 CHESS 与列维比赛
	· 深蓝（ IBM，1996 ）：
		· 1997 年深蓝战胜卡斯帕罗夫，机器首次战胜人类世界冠军

###### · 强化学习：围棋和 AlphaGo
· 2016 年 3 月，4 比 1 战胜围棋世界冠军李世石
· 2016 年至 2017 年，与中日韩数十位围棋高手进行快棋对决，连续 60 局无一败绩
· 2017 年 5 月，在中国乌镇与排名世界第一的世界围棋冠军柯洁对战，以 3 比 0 获胜
· AlphaGo 首次使用*强化学习*，谷歌旗下 DeepMind
	· 1980 年代由*巴托*和*萨顿*提出
	· 强化学习以马尔可夫决策过程和动态规划为理论基础
	· 智能体（Agent）以*试错*方式进行学习，通过与环境进行交互获得的奖赏指导行为，目标是使智能体*获得最大的奖赏值*

###### · 决策式 AI 和生成式 AI：
1. 决策式 AI（深度学习、强化学习、深度强化学习）：
· 学习数据中的**条件概率分布**，即一个样本属于特定类别的概率，再对新的场景进行判断、分析和预测
2. 生成式 AI（GPT-3，ChatGPT，GPT-4）：
· 学习数据中的**联合概率分布**，即数据中多个变量组成的向量的概率分布，对已有的数据进行总结归纳，自动生成全新的内容


### 贰  数学建模与最优化的背景

#### 述：
#####
#####

###### · 运筹学：
· 运筹学是20世纪三四十年代发展起来的一门新兴交叉学科，主要研究人类对各种资源的运用及筹划，在满足一定约束的条件下，以期发挥有限资源的最大效益，达到总体最优的目标
· 运筹学最初由钱学森老先生引入中国，最开始的用途是优化航空／军工等领域
· 运筹学在不同领域的应用：
	· 路径优化问题（Routing Problem）--交通领域（GPS 导航）
	· 仓储、运输等物流（Logistics）以及供应链（Supply chain）领域
	· 制造业里的生产流程优化（Process Optimization）
	· 电力领域的电网的布局以及分配（Power Grid）
	· 电子工程里的设施部件分配问题（Facility Layout Problem）
	· 能源领域的优化，如：如何铺设输油管道
	· 火车、课程、飞机时刻表安排问题等调度问题（Scheduling Problem）
	· 资产配置（Asset Allocation）、风险控制（risk management）等经济金融领域的应用
· 综上所述，运筹学里的优化模型作为数学建模里的一种模型，在各个领域被广泛应用；运筹学里的优化算法作为数值解决各类优化问题的关键，应用更为广泛，例如统计模型最后基本归结为求解一个优化问题（如最大似然估计）
· 简单地说：凡是有“**最**”字，如：利润最大化、成本最小化，基本就和运筹学息息相关

###### · 数学模型的分类：
· 按是否考虑随机因素分类：
	· 确定性模型
	· 随机性模型
· 按是否考虑模型的变化分类：
	· 静态模型
	· 动态模型
· 按应用离散方法或连续方法：
	· 离散模型
	· 连续模型
· 按建立模型的数学方法分类：
	· 几何模型
	· 微分方程模型
	· 图论模型
	· 规划论模型
	· 马氏链模型

###### <font color="#00bbff">· 问题：椅子能在不平的地面放稳吗？</font>
```C++
· 问题分析：
	· 通常情况下，椅子三只脚着地
	· 放平稳指的是椅子的四只脚全部着地
```
```C++
· 模型假设：
1. 椅子的四条腿一样长，椅脚与地面点接触，四角连线呈正方形
2. 地面高度连续变化，可视为数学上的连续曲面（不考虑山峰或悬崖的地形）
3. 地面相对平坦，使椅子在任意位置至少三只脚同时着地
```
```C++
· 模型构成：
用数学语言把椅子的四只脚着地的关系表示出来
1. 椅子位置：利用正方形（椅角连线）的对称性，用 θ（对角线与 x 轴夹角）表示椅子位置
2. 四只脚着地：椅脚与地面距离为零，距离是 θ 的函数
3. 四个距离（四只脚）可以利用正方形的对称性化为两个距离：
	· A，C 两脚与地面距离之和 f(θ)
	· B，D 两脚与地面距离之和 g(θ)
```
![[最优化方法图/最优化方法图1-2.png|350]]
                           （图二：正方形 ABCD 绕 O 点旋转）
```C++
· 模型构成：
1. 地面为连续曲面 => f(θ) 与 g(θ) 是连续函数
2. 椅子在任意位置至少三只脚着地 => 对任意一个 θ，f(θ) 和 g(θ) 至少一个为零
```
```C++
· 数学问题：
	· 已知：f(θ)，g(θ) 是连续函数；对任意 θ，f(θ)·g(θ) = 0；且 g(0) = 0，f(0) ＞ 0
	· 证明：存在 θ*，使 f(θ*) = g(θ*) = 0
```
```C++
· 模型求解：
将椅子旋转 90°，对角线 AC 和 BD 互换
由 g(0) = 0，f(0) ＞ 0，知 f(π/2) = 0，g(π/2) ＞ 0
令 h(θ) = f(θ) - g(θ)，则 h(0) ＞ 0，h(π/2) ＜ 0
由 f，g 的连续性和 h 为连续函数，据连续函数的基本性质，必存在 θ*，使 h(θ*) = 0，即 f(θ*) = g(θ*)
因为 f(θ)·g(θ)=0，所以 f(θ*) = g(θ*) = 0
```
```C++
· 评注和思考：
建模的关键：θ 和 f(θ)，g(θ) 的确定；假设条件的本质和非本质
再考察四脚呈长方形的椅子
```

###### · 数学建模的方法和步骤：

· ***数学建模的基本方法***：
· 机理分析：根据对客观事物特性的认识，找出反应内部机理的数量规律
· 测试分析：将对象看作“黑箱”，通过对量测数据的统计分析，找出与数据拟合最好的模型
· 二者结合：用机理分析建立模型结构，用测试分析确定模型参数
· 机理分析没有统一的方法，主要通过实例研究（Case Studies）来学习

· ***数学建模的一般步骤***：
![[最优化方法图/最优化方法图1-3.png|450]]
                               （图三：数学建模的一般步骤）
· 模型准备：了解实际背景，明确建模目的，搜集有关信息，掌握对象特征，形成一个比较清晰的“问题”
· 模型假设：针对问题特点和建模目的，作出合理的、简化的假设，在合理与简化之间作出折中
· 模型构成：用数学的语言、符号描述问题，发挥想象力，使用类比法，尽量采用简单的数学工具
· 模型求解：各种数学方法、软件和计算机技术
· 模型分析：如结果的误差分析、统计分析、模型对数据的稳定性分析
· 模型检验：与实际现象、数据比较，检验模型的合理性、适用性
· 模型应用

· ***数学建模的全过程***：
![[最优化方法图/最优化方法图1-4.png|550]]
                      （图四：数学建模是现实世界和数学世界的桥梁）
· 表述：根据建模目的和信息将实际问题“翻译”成数学问题
· 求解：选择适当的数学方法求得数学模型的解答
· 解释：将数学语言表述的解答“翻译”回实际对象
· 验证：用现实对象的信息检验得到的解答
· 实践 => 理论 => 实践

· ***最优化的基本概念***：
· 最优化技术是一门较新的学科分支，它是在本世纪五十年代初在电子计算机广泛应用的推动下才得到迅速发展，并成为一门直到目前仍然十分活跃的新兴学科
· 最优化所研究的问题是在众多的可行方案中怎样选择最合理的一种以达到最优目标
· 将达到最优目标的方案称为最优方案或最优决策，搜寻最优方案的方法称为最优化方法，关于最优化方法的数学理论称为最优化论
· 最优化问题至少有两要素：一是可能的方案；二是要追求的目标，后者是前者的函数
· 如果第一要素与时间无关就称为静态最优化问题，否则称为动态最优化问题

1. 最优化技术工作被分成两个方面，一是由实际生产或科技问题形成最优化的数学模型，二是对所形成的数学问题进行数学加工和求解
2. 对于第二方面的工作，目前已有一些较系统成熟的资料，但对于第一方面工作即如何由实际问题抽象出数学模型，目前很少有系统的资料，而这一工作在应用最优化技术解决实际问题时是十分关键的基础，没有这一工作，最优化技术将成为无水之源，难以健康发展

###### <font color="#00b0f0">· 问题：定体积圆柱体取什么尺寸表面积最小？</font>
· 最优化在物质运输、自动控制、机械设计、采矿冶金、经济管理等科学技术各领域中有广泛应用
· 下面举几个专业性不强的实例

```C++
· 问题描述：
把半径为1的实心金属球熔化后，铸成一个实心圆柱体，问圆柱体取什么尺寸才能使它的表面积最小？
```
```C++
· 模型求解：
决定圆柱体表面积大小有两个决策变量：圆柱体地面半径 r，高 h
问题的约束条件是所铸圆柱体的重量与原来的球相等，即：
```
$$\pi r^2h\rho=\frac{4}{3}\pi R^3\rho\enspace (\rho 为金属比重，\rho\neq0,R=1)$$即为$$\pi r^2h=\frac{4}{3}\pi R^3$$进一步代入化简得：$$r^2h-\frac{4}{3}=0$$
```C++
问题所追求的目标是圆柱体表面积最小，即：
```
$$min(2\pi rh+2\pi r^2)$$
```C++
于是得原问题的数学模型：
```
$$\begin{cases}min(2\pi rh+2\pi r^2)\\ s.t.\ \ \ \ r^2h-\frac{4}{3}=0\end{cases}$$
```C++
· 问题的求解：
利用在高等数学中所学的 Largrange 乘子法可求解本问题：
```
$$L(r,h,\lambda)=2\pi rh+2\pi r^2-\lambda(r^2h-\frac{4}{3})$$
```C++
分别对 r，h，λ 求偏导数，并令其等于零，有：
```
$$\begin{cases}\frac{\partial L}{\partial r}=2\pi h+4\pi r-2rh\lambda=0\\ \frac{\partial L}{\partial h}=2\pi r-\lambda r^2=0\\ \frac{\partial L}{\partial \lambda}=-r^2h+\frac{4}{3}=0\end{cases}\Rightarrow h=2r$$$$\Rightarrow r=\sqrt[3]\frac{2}{3},\enspace h=2\sqrt[3]\frac{2}{3}$$

###### · 优化问题的一般形式：
· 优化问题的三要素：决策变量，目标函数，约束条件
![[最优化方法图/最优化方法图1-5.png|450]]
                               （图五：优化问题是三要素）
· 可行解：满足约束的解
· 可行域：可行解的集合
· 最优解：取到最小或最大值的可行解

###### · 线性规划：
· 线性规划问题中，目标函数和约束条件都是线性函数
· 线性规划模型的标准型：
![[最优化方法图/最优化方法图1-6.png]]
（图六：线性规划模型的标准型）

· 线性规划的其他形式可通过*形式变换*和*添加松弛变量*而化为标准型
· 常用求解方法：**单纯形法**

· <font color="#ffc000">线性规划例 1</font>：
```C++
· 问题：
某豆腐店用黄豆制作两种不同口感的豆腐出售：
1. 制作口感较鲜嫩的豆腐每千克需要 0.3 千克一级黄豆及 0.5 千克二级黄豆，售价10元；
2. 制作口感较厚实的豆腐每千克需要 0.4 千克一级黄豆及 0.2 千克二级黄豆，售价5元
问：现小店购入 9 千克一级黄豆和 8 千克二级黄豆，应如何安排制作计划才能获得最大收益？
```
```C++
· 问题前期分析：
该问题是在不超出制作两种不同口感豆腐所需黄豆总量条件下合理安排制作计划，使得售出各种豆腐能获得最大收益

· 模型假设：
1. 假设制作的豆腐能全部售出
2. 假设豆腐售价无波动

· 变量假设：
设计划制作口感鲜嫩和厚实的豆腐各 x1 千克和 x2 千克，可获得收益 R 元

· 目标函数：获得的总收益最大：
```
$$\begin{cases}总收益可表示为：R=10x_1+5x_2\\ 受一级黄豆数量限制：0.3x_1+0.4x_2\leq 9\\ 受二级黄豆数量限制：0.5x_1+0.2x_2\leq 8\end{cases}$$
```C++
综上分析：得到该问题的线性规划模型：
```
$$maxR=10x_1+5x_2$$$$s.t.\ \ \ \ \begin{cases}0.3x_1+0.4x_2\leq 9\\ 0.5x_1+0.2x_2 \leq 8\\ x_1,x_2\geq 0\end{cases}$$
· 用 Matlab 编程求解程序如下：
```matlab
f = -[10 5];
A = [0.3 0.4;0.5 0.2];
B = [9;8];
[X,FVAL,EXITFLAG,OUTPUT] = linprog(f,A,B)
```
```C++
得到结果：
x =
	10.0000
	15.0000
FVAL =
	-175.0000
```

· <font color="#ffc000">线性规划例 2</font>：
```C++
· 问题：
1. 设某工厂有甲、乙、丙、丁四个车间，生产A、B、C、D、E、F六种产品
2. 根据机床性能和以前的生产情况，得知每单位产品所需车间的工作小时数、每个车间在一个季度工作小时的上限以及单位产品的利润，如下表所示（例如，生产一个单位的 A 产品，需要甲、乙、丙三个车间分别工作 1 小时, 2 小时和 4 小时）
问：每种产品各应该每季度生产多少，才能使这个工厂每季度生产利润达到最大？
```
![[最优化方法图/最优化方法图1-7.png|450]]
                                （图七：车间工作情况表）
```C++
· 问题分析：
	· 这是一个典型的最优化问题，属线性规划
	· 假设：产品合格且能及时销售出去；工作无等待情况等
	· 变量说明：
        xj：第 j 种产品的生产量（j=1,2,……,6）
        aij：第 i 车间生产单位第 j 种产品所需工作小时数
               （i=1,2,3,4; j=1,2,……,6）
        bi：第 i 车间的最大工作上限
        cj：第 j 种产品的单位利润
则：    cj·xj：第 j 种产品的利润总额
       aij·xj：第 i 车间生产第 j 种产品所花时间总数

· 于是，可以建立如下数学模型：
```
$$max\ z=\Sigma^6_{j=1}c_jx_j$$$$s.t.\ \ \ \ \begin{cases}\Sigma_{j=1}^6a_{ij}x_j\leq b_i,\enspace i=1,2,3,4\\ 0\leq x_j\leq\frac{b_i}{\max_{(1\leq i\leq 4)}\{a_{ij}\}},且为整数,\enspace j=1,2,3,4,5,6\end{cases}$$
· 计算结果：

| Z（百元） | $x_1$ | $x_2$ | $x_3$ | $x_4$ | $x_5$ | $x_6$ |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 1320  | 0     | 0     | 60    | 40    | 100   | 40    |

###### · 最优化：
![[最优化方法图/最优化方法图1-8.png|450]]
                            （图八：最优化问题的一般形式）
· 在实际应用中,可以将求最大值的目标函数取相反数后统一成公式中求最小值的形式

· **相关定义**：
1. *可行解*：满足约束条件（1.2）和（1.3）的 x 称为可行解，也成为可行点或容许点
2. *可行域*：全体可行解构成的集合称为可行域，也称为容许集，记为 D，即：$$D=\{x\ |\ h_i(x)=0,\ i=1,\ldots,m,\ g(x)\geq 0,\ j=1,\ldots,p,\ x\in R^n\}$$若 $h_i(x)$ 和 $g_j(x)$ 为连续函数，则 D 为闭集
3. *整体最优解*：若 $x^*\in D$，对于一切 $x\in D$ 恒有 $f(x^*)\leq f(x)$，则称 $x^*$ 为最优化问题（P）的整体最优解；若 $x^*\in D,\ \ x\neq x^*$，恒有 $f(x^*)\textless f(x)$，则称 $x^*$ 为最优化问题（P）的严格整体最优解
4. *局部最优解*：若 $x^*\in D$，存在 $x^*$ 的某邻域 $N_\varepsilon(x^*)$，使得对于一切 $x\in D\cap N_\varepsilon(x^*)$，恒有 $f(x^*)\leq f(x)$，则称最优化问题（P）的局部最优解，其中 $N_\varepsilon(x^*)=\{x\ |\lVert x-x^*\rVert\textless \varepsilon,\ \varepsilon\textgreater 0\}$
	· 当 $x\neq x^*$ 时，若上面的不等式为严格不等式则称 $x^*$ 为问题（P）的严格局部最优解
	· 显然，整体最优解一定是局部最优解；而局部最优解不一定是整体最优解
	· $x^*$ 对应的目标函数值 $f(x^*)$ 称为最优值，记为 $f^*$
· 求解最优化问题（P），就是求目标函数 $f(x)$ 在约束条件（1.2）和（1.3）下的极小点，实际上是求可行域 D 上的整体最优解；但是一般情况下，整体最优解是很难求出的，往往只能求出局部最优解

· 给出一个最优化问题，一定能求到最优解吗？
	· 张益唐：孪生素数猜想
	· 望月新一：ABC 猜想
	· 佩雷尔曼：庞加莱猜想

###### · NP 问题与计算复杂度：
· 几个概念：
	1. P 问题（Polynomial problem）：
		如果一个问题可以找到一个能在多项式的时间里解决它的算法，那么这个问题就属于 P 问题
	2. NP 问题（Non-deterministic polynomial problem）：
		NP 问题是指可以在多项式的时间里验证一个解的问题
	3. NP-completeness：
		①该问题是一个 NP 问题
		②所有 NP 问题都可以归约到该问题
	4. NP-hard：
		所有的 NP 问题都可以归约到该问题

· 背包问题：
问题描述：背包大小为 W，物品个数为 n，物品 i 的大小为 $w_i$，价值为 $v_i\ (i=1,2,\ldots,n)$，$x_i$ 代表是否将物品 i 装入背包中
$$maxmize\ \Sigma^n_{i=1}v_ix_i$$$$s.t.\ \Sigma^n_{i=1}w_ix_i\leq W,\ and\ x_i\in \{0,1\}$$
输入规模：$$log\ W+\Sigma^n_{i=1}(log\ w_i+log\ v_i)\ \textgreater\ log W=m$$
时间复杂度：$$O(nW)=O(n2^m)$$

· 计算复杂性理论：
	· 计算复杂性理论研究各种可计算问题在计算过程中资源（如时间、空间等）的耗费情况
	· 算法复杂性是对算法效率的度量，它是评价算法优劣的重要依据
	· 时间复杂度：计算所需的步数或指令条数
	· 空间复杂度：计算所需的存储空间大小
在计算机科学中，算法的时间复杂度是一个函数，它定量描述了该算法的运行时间，这是一个代表算法输入值的字符串长度的函数；时间复杂度常用大写的 “O” 表述，不包括这个函数的低阶项和首项系数；使用这种方式时，时间复杂度可被称为是*渐近*的，亦即考察输入值大小趋近无穷时的情况【时间复杂度并不是表示一个程序解决问题需要花多少时间，而是当问题规模扩大后，程序需要的时间长度增长得有多快】
![[最优化方法图/最优化方法图1-9.png|400]]
                         （图九：复杂性在不同问题规模下的影响）

· **指数灾难**：随着问题规模的增长，计算量呈指数增长
![[最优化方法图/最优化方法图1-10.png|300]]
                               （图十：指数增长的“灾难”）
· *旅行商问题（货郎担问题，TSP）的枚举*：
给定 n 个城市，任意两个城市间有路相连，推销员从一个城市出发，不重复的遍历所有的城市并回到起点，求一条路程最短的路径【复杂度为 $O(n!)$ 】
![[最优化方法图/最优化方法图1-11.png|350]]
                            （图十一：TSP 问题的枚举复杂度）

· 问题求解的难易度
![[最优化方法图/最优化方法图1-12.png]]
（图十二：时间复杂度函数）
· 一个问题，如果能找到具有多项式时间复杂度的算法，那么这就是一个“容易解决的问题”
· 是否所有的问题都可以找到复杂度为多项式时间级的算法？
——并不是：比如“输出从 1 到 n 这 n 个数的全排列”这样的问题，不管使用什么样的方法，算法复杂度都是阶乘级，因为总得用阶乘级的时间打印出结果来

· **NP 问题（Non-deterministic Polynomial Problem）**：
· 非确定算法：***猜测***一个变量的真值赋值检查该赋值是否满足
· NP 类问题：由非确定性算法在多项式时间内可计算的判定问题所组成的集合
· 一个更通俗的定义：可以在多项式时间内验证一个解的问题
· NP类问题数量巨大，如完全子图问题、图的着色问题、哈密顿回路问题、以及旅行商问题等

· 定义 NP 问题的意义：
1. 通常只有 NP 问题才可能找到多项式时间的算法：
	因为不能指望一个连多项式时间验证解都无法做到的问题还能存在一个能解决它的多项式时间级的算法
2. 所有的 P 类问题都是 NP 问题：
	能多项式时间解决一个问题，必然能多项式时间验证该问题的解（验证任意给定的解只需要比较即可）
3. P=NP ？
	千禧年难题的简单描述：证明或推翻 P=NP

###### · NP 完全问题与归约：
· 千禧年大奖难题（2000年，美国克雷研究所，100万美元大奖）：
1. 庞加莱猜想：1854-1912，公认的 19 世纪后期的领袖数学家
2. NP - 完全问题：**库克 & 卡普**
3. 霍奇猜想
4. 黎曼假设
5. 杨 - 米尔斯理论
6. 纳维叶 - 斯托克斯方程
7. 贝赫和思维讷通 - 戴尔猜想

· **库克 & 卡普**：
![[最优化方法图/最优化方法图1-13.png|600]]
                   （图十三：斯蒂芬 · 库克 和 理查德 · 卡普 的人物介绍）
![[最优化方法图/最优化方法图1-14.png|450]]
                                （图十四：库克的归约论）

· NP 完全问题（NP-complete problem）：
1. 该问题是一个 NP 问题
2. 所有的 NP 问题都可以归约到该问题
· 库克证明，任取 NP 类中的一个问题，再任取 NP 完全类中的一个问题，则一定存在一个确定性图灵机上的具有多项式时间复杂性的算法，可以把前者转变为后者；这就表明，只要能证明 NP 完全类中有一个问题是属于 P 类的，也就证明了所有的 NP 类题都是 P 类的，即证明了 P=N【 “大海捞针” => “疑似捷径” 】

· **归约（Reducibility）**：Problem A can be reduced to problem B
· 对任意一个问题 A 的输入，可以按照一个转换规则多项式时间内转换为问题 B 的输入，使得两个问题的输出相同
· 库克发明的一种“武器”：证明“B 问题至少和 A 问题一样难”
· 一定存在一个确定性图灵机上的具有多项式时间复杂性的算法，可以把一个 NP 问题转变为 NP 完全问题

· *一元一次方程 向 二元一次方程 的归约*：
· 一元一次方程问题描述：对于任意方程 ax+b=0（a，b 为常数，x 为未知数，且 a≠0），求解 x 的值
· 二元一次方程问题描述：对于任意方程组 $m_1 x+n_1 y+k_1=0\ 和\ m_2 x+n_2 y+k_2=0$$\begin{align*}
(其中m_1  ，n_1，k_1， m_2，n_2，k_2为常数， x， y为未知数，且m_1  ，n_1  ， m_2，n_2  ≠ 0)$目的是求解 x 与 y 的值

· 归约的证明过程：
对于任意一个一元一次方程的实例 $a_1 x+b_1=0$，我们都能构造出一个二元一次方程组实例：$m_{11} x+n_{11} y+k_{11}=0$ 和 $m_{21} x+n_{21} y+k_{21}=0$，令：$m_{11}-m_{21}=a_{1},\ n_{11}-n_{21}=0,\ k_{11}-k_{21}=b_{1}$，此时可以发现，当求解到该二元一次方程组实例的解时，对应的一元一次方程实例也可以求解到同样的解

· 1972 年，时隔一年之后，卡普证明，21 个有关组合优化的问题也全是 NP 完全问题，进一步加强与发展了 NP 完全性理论，这一篇著名的论文是《Reducibility among Combinatorial Problems（组合问题中的可归约性）》【 “疑似捷径” => “捷径” 】

· 目前为止，全世界的研究人员已经证明了上万个问题是 NP 完全的，分布在逻辑、代数、自动机、组合优化等诸多领域以及国民经济生活的各个方面

· **经典 NP 完全问题**：
· 第一个 NP 完全问题（Cook 定理，1971 年）：
	•可满足问题（SAT）是 NP 完全问题
· 6 个 NP 完全问题（Karp，1972 年）：
	· 3 - 可满足问题（3 - SAT）
	· 图的点覆盖问题（VC）
	· 图的 k 点团存在性问题（Clique）
	· 图的哈密顿圈问题（HC）
	· 正整数集合的划分问题
	· 三维匹配问题（3DM）
· 更多的 NP 完全问题：
	· 1979 年：300 多个
	· 1998 年：2000 多个
![[最优化方法图/最优化方法图1-15.png|550]]
                         （图十五：可满足问题与 3 - 可满足问题）
![[最优化方法图/最优化方法图1-16.png|550]]
                               （图十六：顶点覆盖问题）
![[最优化方法图/最优化方法图1-17.png]]（图十七：集合覆盖问题）

· P 问题，NP 问题，NP-C 问题，NP-H 问题的关系：（如今：左图；不知未来有无右图）
![[最优化方法图/最优化方法图1-18.png|500]]
                    （图十八：P，NP，NP-C，NP-H 问题之间的关系）

· 未来展望：
1. 假设证明了 P=NP，那么便可以得出结论：对于破译密码系统这个问题，可以多项式时间求解的，也就是说，理论上，我们可以破解出任意一个密码系统
2. 复杂如星际争霸、魔兽争霸、dota2，亦或是扫雷、超级玛丽、俄罗斯方块之类的游戏，可以被编写出高效的AI，使得电脑玩家的水平无人能及
3. 整数规划、组合优化等运筹学中的难题可以被高效的解决，这个方向的研究将被前所未有的提升：联系到现实，大到公路、铁路、城市规划，小到送餐 APP 配送满意度更高等问题都能被妥善的解决
4. 医学上、生物学等很多已被证明为 NP-C 的问题，如蛋白质的折叠问题等等，都能设计出高效的算法去解决——这无疑是全人类的福音


### 叁  智能搜索初步

#### 述：
#####
#####

###### · 局部搜索（Local Search）的基本思想：
· 局部搜索的应用：
	· 生产计划、生产调度、路径规划、资源配置等
	· 事实上，许多（甚至大多数）运筹问题都可以用局部搜索方法求解（如飞机的航线规划等）
· 局部搜索的基本思想：
	1. 选择初始状态（其本质是猜测初始解）
	2. 做出局部更改使得当前状态得到改进
	3. 重复步骤 2 直到找到目标状态（或者运行超时）
· 局部搜索的具体要求：
	· 产生一个初始解（经常随机产生，很可能不是最优解，甚至不可行）
	· 评价当前解的质量
	· 转移到其他状态（通过定义好的邻域函数）
	· 这些操作的计算速度要快，不要保存后续路径

###### · 登山搜索（Hill-climbing Search）：
· “Like climbing Everest in thick fog with amnesia（就健忘者像在大雾中攀登珠穆朗玛峰）”
· 核心思想：向着更“好”的邻域方向移动
![[最优化方法图/最优化方法图1-19.png|600]]
                         （图十九：登山搜索算法的伪码描述）
（注意：伪码中的 “successor” 就是 “neighbor（邻域）” ）

· 登山搜索通常用于求解“完全”状态问题，即要求所有变量被决策
· 用于求解约束满足问题（Constraint Satisfaction Problem，CSP ）：
	· 允许不满足约束的状态存在
	· 算子能为变量重复赋值
· 变量选择：随机选择任意冲突变量
· 通过*最小冲突启发式算法*选择变量值：
	· 选择违反约束最少的值
	· 例如：登山搜索算法中的 $h(n)=$ 违反约束的个数

· ***皇后问题***：
· 状态：4 个皇后占据 4 列（ 256 个状态）
· 邻域算子：每个皇后只能在其所在列上移动
· 目标：任意两个皇后之间无“攻击”（no attacks）
· 评价函数：$h(n)=$ 攻击数量（number of attacks）
![[最优化方法图/最优化方法图1-20.png|500]]
                    （图二十：皇后问题，通过评价函数判断解的正确性）

· *8 皇后问题*：最小冲突的启发式（Min-Conflicts Heuristic）
1. 生成初始状态（随机）
2. 重复以下过程：
	· 选取一个冲突变量 var（随机）
		· 重新为 var 赋值，使得冲突次数最小
		· 如果新状态没有冲突产生，那么返回该赋值
![[最优化方法图/最优化方法图1-21.png|700]]
                    （图二十一：8 皇后问题的最小冲突的启发式算法）

· 关于登山搜索的评论：
	· 基于登山搜索（最小冲突启发式）的局部搜索算法对于“百万皇后”问题有极好的性能
	· 原因：搜索空间虽然 $O(n^n)$，但合法状态分布集中，意味着整体来看，任意随机生成的状态距离合法状态只有“几步之遥”

· *8 皇后问题的随机登山搜索*：
· 随机登山搜索：从“向上登山”的移动中随机选取下一步（登山搜索可以有许多变形）
· 8 皇后问题：
1. 随机生成初始状态：
![[最优化方法图/最优化方法图1-22.png|225]]
                        （图二十二：8 皇后问题随机生成的初始状态）
	· h = 直接或间接可以相互攻击的皇后的对数
	· 初始状态下：h = 17
	· 算子：在列的方向上移动皇后，通过当前最佳方案，可得 h = 12（图中方块标注）

· 登山搜索的问题：
	· 丘陵地带（Foothills）/局部最优：当前不是全局最优，但是邻域没有更优的解
	· 迷宫（maze）：不得不暂时背离寻找最优解的目标
	· 高原地带（Plateaus）：所有的邻域看上去都一样
		· 对于 8 皇后问题而言，就是下一步怎么走都不会减少攻击数量
	· 山脊（Ridges）：局部最优值次序
	· 忽视最高点：搜索结束了吗？

2. 评价函数 h 的值（可以互相攻击的皇后对数）是多少？
![[最优化方法图/最优化方法图1-23.png|225]]
                        （图二十三：8 皇后问题局部最优解：h = 1 ）
	· 找到下一步改善当前状态的质量

· 登山搜索的局限性：
	· 依赖于初始状态，容易陷入局部最优
![[最优化方法图/最优化方法图1-24.png|450]]
                              （图二十四：“登山”的示意图）
	· 怎样克服局部最优和高原现象？
	——随机重启，登山搜索

###### · 局部束搜索（Local Beam Search）：
· 登山搜索的变形：
	· 随机重启：在指定步以后，简单地随机选取一个状态重新开始登山搜索
	· 局部束搜索：并行运行多个随机初始点，同时维护 k 个最好状态

· 局部束搜索的基本思想：
	· 从 k 个随机产生的状态开始
	· 跟踪 k 个状态（而不是 1 个）
	· 对于每次迭代，产生 k 个状态的所有后继
	· 如果任何一个状态是目标状态，停止；否则选择 k 个最好的后继并重复上述过程

· 局部束搜索是否等价于 k 个随机点重启动的登山搜索（ k random-restart hill-climbing ）？
——不等价：在局部束搜索搜索中 k 个点之间信息共享！
	· 一些点对产生后继最优解没有任何贡献，而一个点可能对所有 k 个点的后继产生贡献
	· “Come over here，the grass is greener”（Russell and Norvig）

· 对局部搜索的改进：
	· 问题：
		· 怎样迅速转移到更好的状态？
		· 怎样避免局部最优 “getting stuck” / local maxima？
	· 思想：引入“向下转移”（噪声）以摆脱局部最优
	· 噪声策略：
		1. 模拟退火（Simulated Annealing）
			· Kirkpatrick et al. 1982; Metropolis et al. 1953
		2. 混合随机行走（Mixed Random Walk）
			· SElman and Kautz 1993

###### · 模拟退火（Simulated Annealing）：
· 基本思想：
	· 采用传统的登山搜索策略，但是不时朝产生改进解的方向移动，即<font color="#ffc000">下山移动（downhill moves）</font>
	· 随着时间的推移，采取下山移动的概率逐渐降低，并且下山移动的步长逐渐减小
	· Kirkpatrick et al. 1982; Metropolis et al. 1953
![[最优化方法图/最优化方法图1-25.png]]
（图二十五：模拟退火算法的实现）

· 关于模拟退火：
	· 基于统计机制的噪声模型
		· 模拟生长晶体物理过程
		· Kirkpatrick et al. 1982, Metropolis et al. 1953
	· 收敛性：
		· W/ exponential schedule，收敛到最优解
		· 可以证明，如果 T 降低足够慢，那么模拟退火可以以接近 1 的概率找到最优解
	· 重要内容：下向 / 侧向移动
		· 开销大，但是能找到最优解（如果有足够时间的话）
	· 每年数百篇论文：
		· 应用：超大规模集成电路布局，工厂调度，蛋白质折叠


### 肆  种群智能

#### 述：
#####
#####

###### · 粒子群优化算法（PSO）：
· 粒子群优化算法（ The Particle Swarm Optimization Algorithm，PSO ），又称“鸟群算法”
![[最优化方法图/最优化方法图1-26.png|250]]
                          （图二十六：粒子群优化算法（鸟群算法））

· **PSO 起源的简述**：
	· 灵感来自大自然的社会行为和动态运动与昆虫，鸟类和鱼类的交流
![[最优化方法图/最优化方法图1-27.png|500]]
                             （图二十七：PSO 的灵感起源）
	· 1986 年，克雷格 · 雷诺兹（Craig Reynolds） 用 3 个简单的行为描述了这个过程：
![[最优化方法图/最优化方法图1-28.png|550]]
                        （图二十八：集群智能三个行为的描述）
~~~
图二十八所描述的三个行为：
1. 分离：避免拥挤与碰撞
2. 协调：向当地同伴的平均方向移动
3. 凝聚：向当地同伴的平均位置移动
~~~

· 优化应用：粒子群优化
· 由 詹姆斯 · 肯尼迪（James Kennedy） 和 拉塞尔 · 埃伯哈特（Russell Eberhart）于 1995 年提出
· 讲自我经验于社群经验结合起来

· **PSO 的概念**：
· 使用许多代理（粒子）组成一个在搜索空间中移动的群体来寻找最佳解决方案
· 搜索空间中的每个粒子根据自身的飞行经验，以及其他粒子的飞行经验来调整自己的“飞行”
· 概念映射：
	· 收集飞行粒子（群）——改变解决方案
	· 搜索区域——可能的解决方案
	· 向一个更舒适的领域移动，以获得全局最优
	· 每个粒子都有自己的轨迹：
		· 个体最优解——局部最优解
		· 粒子群最优解——全局最优解

· 每个粒子根据自身和同伴的飞行经历动态调整其运动速度
· 每个粒子根据：
1. 当前位置与速度
2. 当前位置和局部最优位置之间的距离
3. 当前位置和全局最优位置之间的距离
来修改自己的位置
![[最优化方法图/最优化方法图1-29.png|400]]
                        （图二十九：粒子群算法，实时运动的影响）

· 粒子群算法的邻域概念：
![[最优化方法图/最优化方法图1-30.png]]
（图三十：粒子群算法的邻域表示）

· **粒子群算法的参数**：
· $A$：粒子群
· $p_i$：粒子 $a_i$ 在解空间的位置
· $f$：目标函数
· $v_i$：粒子 $a_i$ 的速率
· $V(a_i)$ 粒子 $a_i$ 的邻域（固定）
· PSO 中的邻域概念与局部搜索中的邻域概念不同，因为 PSO 中每个粒子的邻域永远不会改变（固定的）

· **粒子群算法**：
![[最优化方法图/最优化方法图1-31.png|500]]
                            （图三十一：粒子群算法的伪代码）
```C++
· [x*]=PSO()    / 运行 PSO 算法以寻求最优解 x* /

P=Particle_Initialization()    / 初始化了一组粒子，用 P 表示，每个粒子代表搜索空间中的一个潜在解 /

For i=1 to it_max    / 对于 i 从 1 到 it_max 的每次迭代 /

For each particle p in P do    / 对于 P 中的每个粒子 p /

fp=f(p)    / 计算当前粒子 p 的适应度或目标函数 f 的值 /

If fp is better than f(pBest)：pBest = p    / 如果 fp 优于 f(pBest)，更新粒子当前位置 /

· 条件结束
· 第一层内循环结束

gBest=best p in P    / 在评估所有粒子后，选择所有粒子中适应度最佳的粒子，更新全局最佳位置 gBest /

For each particle p in P do    / 再次遍历每个粒子 /

v = v + c1*rand*(pBest – p) + c2*rand*(gBest – p)
	/ 根据当前速度、当前位置 p 与其最佳已知位置 pBest 之间的差异以及全局最佳位置 gBest 与当前位置 p 之间的差异来更新粒子的速度 v; c1 和 c2 是加速系数，rand 是 0 到 1 范围内的随机数 /

p=p+v    / 根据当前位置和速度更新粒子的位置 p /

· 第二个内循环结束
· 外层循环结束
```

· 其中的粒子更新规则：
```C++
p=p+v
根据：v = v + c1*rand*(pBest – p) + c2*rand*(gBest – p)
```
其中：
· $p$：粒子的位置
· $v$：路径方向
· $c_1$：局部信息权重
· $c_2$：全局信息权重
· $pBest$：单个粒子最优位置
· $gBest$：粒子群的最优位置
· $rand$：随机变量

· 说明：
· 粒子数通常在 10 到 50 之间
· $c_1$ 反映个体最佳价值的重要性
· $c_2$ 反映邻域最佳价值的重要性
· 通常 $c_1+c_2=4$（经验选择的值）
· 如果速度太低 —> 算法太慢
· 如果速度太高 —> 算法不太稳定

· 算法步骤：
1. 创建一个均匀分布在 X 上的代理点（粒子）的“总体”
2. 根据目标函数计算每个粒子的位置
3. 如果粒子的当前位置比之前的最佳位置好，则更新它
4. 确定最佳粒子（根据粒子之前的最佳位置）
5. 更新粒子的速度：
![[最优化方法图/最优化方法图1-32.png]]
（图三十二：更新粒子的速度）
6. 将粒子移动到新的位置：
![[最优化方法图/最优化方法图1-33.png|250]]
                            （图三十三：将粒子移动到新的位置）
7. 继续执行步骤 2，直到满足条件停止

![[最优化方法图/最优化方法图1-34.png]]
（图三十四：PSO 的核心思想步骤）

1. 惯性：使粒子以相同的速度和方向运动
2. 个体影响：提升个体水平；使粒子返回先前的位置，比现在的位置更好
3. 社群影响：使粒子沿着最佳邻域的方向移动

· 强化（Intensification）：探索之前的解决方案，找到给定区域的最佳解决方案
· 多样化（Diversification）：寻找新的解决方案，找到可能有最佳解决方案的地区
![[最优化方法图/最优化方法图1-35.png]]
（图三十五：PSO 中的强化和多样化）

· *算法示例*：
![[最优化方法图/最优化方法图1-36.png|450]]
![[最优化方法图/最优化方法图1-37.png|450]]
![[最优化方法图/最优化方法图1-38.png|450]]
![[最优化方法图/最优化方法图1-39.png|450]]
![[最优化方法图/最优化方法图1-40.png|450]]
![[最优化方法图/最优化方法图1-41.png|450]]
![[最优化方法图/最优化方法图1-42.png|450]]
![[最优化方法图/最优化方法图1-43.png|450]]
                         （图三十六—图四十三：PSO 算法示例）

· **算法特点**：
· 优点：
	· 简单的实现  
	· 易于并行化以进行并发处理  
	· 很少的算法参数  
	· 非常高效的全局搜索算法
· 缺点：
	· 在中间最优点有快速和过早收敛的趋势
	· “精细化”搜索阶段收敛速度慢（局部搜索能力弱）

· **不同的 PSO 算法**：
• 2-D Otsu PSO
• Active Target PSO
• Adaptive PSO
• Adaptive Mutation PSO
• Adaptive PSO Guided by Acceleration Information
• Attractive Repulsive Particle Swarm Optimization
• Binary PSO
• Cooperative Multiple PSO
• Dynamic and Adjustable PSO
• Extended Particle Swarms
…………

~~~
参考：Davoud Sedighizadeh and Ellips Masehian, “Particle Swarm Optimization Methods, Taxonomy and Applications”.
International Journal of Computer Theory and Engineering, Vol. 1, No. 5, December 2009
~~~

###### · 用 PSO 解决装箱问题（Bin Packing Problem，BBP）：

· **用粒子群算法求解多目标装箱问题（Multiobjective Bin Packing Problem）**：

· 问题表述：
1. 多目标二维 BPP
2. 宽度为 W，高度为 H 的空间，I 个箱子
3. 任一项 J 的宽度约束：$w_j\leq W$，高度约束：$h_j\leq H$，权重为 $\psi_j$
4. 目标：
	1. 最小化使用的箱子的数量 K
	2. 将整体重心与期望重心之间的平均偏差最小化

· 初始化：
1. 通常是随机的
2. 在这项工作中：
	1. 解自左下角填充（Bottom Left Fill，*BLF*）的启发式
	2. BLF 对矩形进行排序：
		1. 随机（random）
		2. 根据一定的标准：
			1. 宽度
			2. 重量
			3. 面积
			4. 周长
			 ……
![[最优化方法图/最优化方法图1-44.png|450]]
                               （图四十四：BLF 的初始化）
1. “箱子”移到右边，在顶部检测到交集
2. “箱子”移到顶部，在右侧检测到交集
3. 如果选择插入的可用空间较低，则重新“定点”

· *多目标混合粒子群算法（ HMOPSO ）*：
	· H—hybrid 混合
	· M—multi 多个
	· O—objective 目标
	· P—particle 粒子
	· S—swarm 群体
	· O—optimization 最优化
![[最优化方法图/最优化方法图1-45.png|350]]
                            （图四十五：HMOPSO 的流程图）

阶段 1：
	· 2 个箱子之间的部分交换
	· 合并 2 个箱子
	· 拆分 1 箱
阶段 2：  
	· 随机旋转
阶段 3：
	· 随机洗牌
![[最优化方法图/最优化方法图1-46.png|350]]
                            （图四十六：单个粒子的突变模式）

· 用 PSO 解决 BPP 的模拟：
1. 随机生成 6 个类 20 个实例
2. 范围大小：
	1. Class 1：【0，100】
	2. Class 2：【0，25】
	3. Class 3：【0，50】
	4. Class 4：【0，75】
	5. Class 5：【25，75】
	6. Class 6：【25，50】
	· Class 2：小物件 —> 更难打包

	· HMOPOS 与 MOPSO（Multiobjective PSO）及 MOEA（Multiobjective Evolutionary Algorithm）算法的比较
	· 参数定义：
![[最优化方法图/最优化方法图1-47.png|450]]
                   （图四十七：HMOPSO、MOPSO 和 MOEA 比较参数）
	· 元启发式算法与分支定界法（BB）在单目标 BPP 上的性能比较
	· 比较每个算法在 10 次运行中的结果
	· HMOPSO 能够在 6 个类的测试实例中的 5 类中进化出比 BB 更优的解决方案
![[最优化方法图/最优化方法图1-48.png|600]]
    （图四十八：BB、MOEA、MOPSO、HMOPSO 有限步骤（10 步）内获取最优解个数的比较）

· *计算效率*：
· 计算效率是指在计算机程序中，用最少的时间和资源完成任务的能力
	· 在 1000 次迭代之后停止，或者在过去的 5 代中没有任何改进
	· 与其他两种相比，MOPSO 获得了较差的结果：
![[最优化方法图/最优化方法图1-49.png|350]]
               （图四十九：HPSO、MOEA、MOPSO 在计算效率上的比较结果图）

· *PSO 解决 BPP 的研究结论结论*：
· 建立 MOBPP-2D 数学模型，基于 HMOPSO 求解 MOBPP-2D 问题
· 选择 BLF（自左下开始填充） 作为解码启发式
· HMOPSO 是一种鲁棒的搜索优化算法：
	· 创建可变长度的数据结构
	· 专门化变异算子
· HMOPSO 在性能指标上的表现一直很好，具有最佳的平均性能
· HMOPSO 在本文中使用的大多数测试用例中，性能优于 MOPSO 和 MOEA

